"use strict";
Object.defineProperty(exports, "__esModule", { value: !0 });
var diffMatchPatch$1 = require("@sanity/diff-match-patch"), groupBy = require("lodash/groupBy.js"), mendoza = require("mendoza"), rxjs = require("rxjs"), xstate = require("xstate");
function _interopDefaultCompat(e) {
  return e && typeof e == "object" && "default" in e ? e : { default: e };
}
var groupBy__default = /* @__PURE__ */ _interopDefaultCompat(groupBy);
function getMutationDocumentId(mutation) {
  if (mutation.type === "patch")
    return mutation.id;
  if (mutation.type === "create")
    return mutation.document._id;
  if (mutation.type === "delete")
    return mutation.id;
  if (mutation.type === "createIfNotExists" || mutation.type === "createOrReplace")
    return mutation.document._id;
  throw new Error("Invalid mutation type");
}
const urlAlphabet = "useandom-26T198340PX75pxJACKVERYMINDBUSHWOLF_GQZbfghjklqvwyzrict";
let nanoid = (size = 21) => {
  let id = "", bytes = crypto.getRandomValues(new Uint8Array(size));
  for (; size--; )
    id += urlAlphabet[bytes[size] & 63];
  return id;
};
function safeGetElementAt(array, index) {
  if (index < 0 || index >= array.length)
    throw new Error("Index out of bounds");
  return array[index];
}
function startsWith(parentPath, path) {
  return parentPath.length <= path.length && parentPath.every(
    (segment, i) => isElementEqual(segment, safeGetElementAt(path, i))
  );
}
function isElementEqual(segmentA, segmentB) {
  return isKeyElement(segmentA) && isKeyElement(segmentB) ? segmentA._key === segmentB._key : isIndexElement(segmentA) ? Number(segmentA) === Number(segmentB) : segmentA === segmentB;
}
function isKeyElement(segment) {
  return typeof segment?._key == "string";
}
function isIndexElement(segment) {
  return typeof segment == "number";
}
function isKeyedElement(element) {
  return typeof element == "object" && "_key" in element && typeof element._key == "string";
}
function isArrayElement(element) {
  return typeof element == "number" || isKeyedElement(element);
}
function isPropertyElement(element) {
  return typeof element == "string";
}
function getAtPath(path, value) {
  if (path.length === 0)
    return value;
  let current = value;
  for (const head of path) {
    if (isArrayElement(head)) {
      if (!Array.isArray(current))
        return;
      if (isKeyedElement(head)) {
        current = current.find((item) => item._key === head._key);
        continue;
      }
      current = current[head];
      continue;
    }
    current = current[head];
  }
  return current;
}
const IS_DOTTABLE = /^[a-z_$]+/;
function stringifySegment(segment, hasLeading) {
  return Array.isArray(segment) ? `[${segment[0]}:${segment[1] || ""}]` : typeof segment == "number" ? `[${segment}]` : isKeyedElement(segment) ? `[_key==${JSON.stringify(segment._key)}]` : typeof segment == "string" && IS_DOTTABLE.test(segment) ? hasLeading ? segment : `.${segment}` : `['${segment}']`;
}
function stringify(pathArray) {
  return pathArray.map((segment, i) => stringifySegment(segment, i === 0)).join("");
}
function isObject(val) {
  return val !== null && typeof val == "object" && !Array.isArray(val);
}
function keyOf(value) {
  return value !== null && typeof value == "object" && typeof value._key == "string" && value._key || null;
}
function findTargetIndex(array, pathSegment) {
  if (typeof pathSegment == "number")
    return normalizeIndex(array.length, pathSegment);
  if (isKeyedElement(pathSegment)) {
    const idx = array.findIndex((value) => keyOf(value) === pathSegment._key);
    return idx === -1 ? null : idx;
  }
  throw new Error(
    `Expected path segment to be addressing a single array item either by numeric index or by '_key'. Instead saw ${JSON.stringify(
      pathSegment
    )}`
  );
}
function getTargetIdx(position, index) {
  return position === "before" ? index : index + 1;
}
function normalizeIndex(length, index) {
  if (length === 0 && (index === -1 || index === 0))
    return 0;
  const normalized = index < 0 ? length + index : index;
  return normalized >= length || normalized < 0 ? null : normalized;
}
function splice(arr, start, deleteCount, items) {
  const copy = arr.slice();
  return copy.splice(start, deleteCount, ...items || []), copy;
}
function insert(op, currentValue) {
  if (!Array.isArray(currentValue))
    throw new TypeError('Cannot apply "insert()" on non-array value');
  const index = findTargetIndex(currentValue, op.referenceItem);
  if (index === null)
    throw new Error(`Found no matching array element to insert ${op.position}`);
  return currentValue.length === 0 ? op.items : splice(currentValue, getTargetIdx(op.position, index), 0, op.items);
}
function upsert(op, currentValue) {
  if (!Array.isArray(currentValue))
    throw new TypeError('Cannot apply "upsert()" on non-array value');
  if (op.items.length === 0)
    return currentValue;
  const replaceItemsMap = [], insertItems = [];
  if (op.items.forEach((itemToBeUpserted, i) => {
    const existingIndex = currentValue.findIndex(
      (existingItem) => existingItem?._key === itemToBeUpserted._key
    );
    existingIndex >= 0 ? replaceItemsMap[existingIndex] = i : insertItems.push(itemToBeUpserted);
  }), replaceItemsMap.length === 0 && insertItems.length == 0)
    return currentValue;
  const next = [...currentValue];
  for (const i of replaceItemsMap)
    next[i] = op.items[replaceItemsMap[i]];
  return insert(
    {
      type: "insert",
      items: insertItems,
      referenceItem: op.referenceItem,
      position: op.position
    },
    next
  );
}
function replace(op, currentValue) {
  if (!Array.isArray(currentValue))
    throw new TypeError('Cannot apply "replace()" on non-array value');
  const index = findTargetIndex(currentValue, op.referenceItem);
  if (index === null)
    throw new Error("Found no matching array element to replace");
  return splice(currentValue, index, op.items.length, op.items);
}
function remove(op, currentValue) {
  if (!Array.isArray(currentValue))
    throw new TypeError('Cannot apply "remove()" on non-array value');
  const index = findTargetIndex(currentValue, op.referenceItem);
  if (index === null)
    throw new Error("Found no matching array element to replace");
  return splice(currentValue, index, 1, []);
}
function truncate(op, currentValue) {
  if (!Array.isArray(currentValue))
    throw new TypeError('Cannot apply "truncate()" on non-array value');
  return typeof op.endIndex == "number" ? currentValue.slice(0, op.startIndex).concat(currentValue.slice(op.endIndex)) : currentValue.slice(0, op.startIndex);
}
function set(op, currentValue) {
  return op.value;
}
function setIfMissing(op, currentValue) {
  return currentValue ?? op.value;
}
function unset(op) {
}
function inc(op, currentValue) {
  if (typeof currentValue != "number")
    throw new TypeError('Cannot apply "inc()" on non-numeric value');
  return currentValue + op.amount;
}
function dec(op, currentValue) {
  if (typeof currentValue != "number")
    throw new TypeError('Cannot apply "dec()" on non-numeric value');
  return currentValue - op.amount;
}
const hasOwn = Object.prototype.hasOwnProperty.call.bind(
  Object.prototype.hasOwnProperty
);
function isEmpty(v) {
  for (const key in v)
    if (hasOwn(v, key))
      return !1;
  return !0;
}
function omit(val, props) {
  const copy = { ...val };
  for (const prop of props)
    delete copy[prop];
  return copy;
}
function unassign(op, currentValue) {
  if (!isObject(currentValue))
    throw new TypeError('Cannot apply "unassign()" on non-object value');
  return op.keys.length === 0 ? currentValue : omit(currentValue, op.keys);
}
function assign(op, currentValue) {
  if (!isObject(currentValue))
    throw new TypeError('Cannot apply "assign()" on non-object value');
  return isEmpty(op.value) ? currentValue : { ...currentValue, ...op.value };
}
function diffMatchPatch(op, currentValue) {
  if (typeof currentValue != "string")
    throw new TypeError('Cannot apply "diffMatchPatch()" on non-string value');
  return diffMatchPatch$1.applyPatches(diffMatchPatch$1.parsePatch(op.value), currentValue)[0];
}
var operations = /* @__PURE__ */ Object.freeze({
  __proto__: null,
  assign,
  dec,
  diffMatchPatch,
  inc,
  insert,
  remove,
  replace,
  set,
  setIfMissing,
  truncate,
  unassign,
  unset,
  upsert
});
function applyOp(op, currentValue) {
  if (!(op.type in operations))
    throw new Error(`Invalid operation type: "${op.type}"`);
  return operations[op.type](op, currentValue);
}
function applyPatches(patches, document) {
  return patches.reduce(
    (prev, patch2) => applyNodePatch(patch2, prev),
    document
  );
}
function applyNodePatch(patch2, document) {
  return applyAtPath(patch2.path, patch2.op, document);
}
function applyAtPath(path, op, value) {
  if (!isNonEmptyArray(path))
    return applyOp(op, value);
  const [head, ...tail] = path;
  if (isArrayElement(head) && Array.isArray(value))
    return applyInArray(head, tail, op, value);
  if (isPropertyElement(head) && isObject(value))
    return applyInObject(head, tail, op, value);
  throw new Error(
    `Cannot apply operation of type "${op.type}" to path ${stringify(
      path
    )} on ${typeof value} value`
  );
}
function applyInObject(head, tail, op, object) {
  const current = object[head];
  if (current === void 0 && tail.length > 0)
    return object;
  const patchedValue = applyAtPath(tail, op, current);
  return patchedValue === current ? object : { ...object, [head]: patchedValue };
}
function applyInArray(head, tail, op, value) {
  const index = findTargetIndex(value, head);
  if (index === null || index === -1)
    return value;
  const current = value[index], patchedItem = applyAtPath(tail, op, current);
  return patchedItem === current ? value : splice(value, index, 1, [patchedItem]);
}
function isNonEmptyArray(a) {
  return a.length > 0;
}
function applyPatchMutation(mutation, document) {
  if (mutation.options?.ifRevision && document._rev !== mutation.options.ifRevision)
    throw new Error("Revision mismatch");
  if (mutation.id !== document._id)
    throw new Error(
      `Document id mismatch. Refusing to apply mutation for document with id="${mutation.id}" on the given document with id="${document._id}"`
    );
  return applyPatches(mutation.patches, document);
}
function hasId(doc) {
  return "_id" in doc;
}
function assignId(doc, generateId) {
  return hasId(doc) ? doc : { ...doc, _id: generateId() };
}
function applyAll(current, mutation) {
  return mutation.reduce((doc, m) => {
    const res = applyDocumentMutation(doc, m);
    if (res.status === "error")
      throw new Error(res.message);
    return res.status === "noop" ? doc : res.after;
  }, current);
}
function applyDocumentMutation(document, mutation) {
  if (mutation.type === "create")
    return create(document, mutation);
  if (mutation.type === "createIfNotExists")
    return createIfNotExists(document, mutation);
  if (mutation.type === "delete")
    return del(document, mutation);
  if (mutation.type === "createOrReplace")
    return createOrReplace(document, mutation);
  if (mutation.type === "patch")
    return patch(document, mutation);
  throw new Error(`Invalid mutation type: ${mutation.type}`);
}
function create(document, mutation) {
  if (document)
    return { status: "error", message: "Document already exist" };
  const result = assignId(mutation.document, nanoid);
  return { status: "created", id: result._id, after: result };
}
function createIfNotExists(document, mutation) {
  return hasId(mutation.document) ? document ? { status: "noop" } : { status: "created", id: mutation.document._id, after: mutation.document } : {
    status: "error",
    message: "Cannot createIfNotExists on document without _id"
  };
}
function createOrReplace(document, mutation) {
  return hasId(mutation.document) ? document ? {
    status: "updated",
    id: mutation.document._id,
    before: document,
    after: mutation.document
  } : { status: "created", id: mutation.document._id, after: mutation.document } : {
    status: "error",
    message: "Cannot createIfNotExists on document without _id"
  };
}
function del(document, mutation) {
  return document ? mutation.id !== document._id ? { status: "error", message: "Delete mutation targeted wrong document" } : {
    status: "deleted",
    id: mutation.id,
    before: document,
    after: void 0
  } : { status: "noop" };
}
function patch(document, mutation) {
  if (!document)
    return {
      status: "error",
      message: "Cannot apply patch on nonexistent document"
    };
  const next = applyPatchMutation(mutation, document);
  return document === next ? { status: "noop" } : { status: "updated", id: mutation.id, before: document, after: next };
}
function applyMutations(mutations, dataset) {
  const updatedDocs = /* @__PURE__ */ Object.create(null);
  for (const mutation of mutations) {
    const documentId = getMutationDocumentId(mutation);
    if (!documentId)
      throw new Error("Unable to get document id from mutation");
    const before = updatedDocs[documentId]?.after || dataset.get(documentId), res = applyDocumentMutation(before, mutation);
    if (res.status === "error")
      throw new Error(res.message);
    res.status !== "noop" && (res.status === "updated" || res.status === "created" || res.status === "deleted") && (documentId in updatedDocs || (updatedDocs[documentId] = { before, after: void 0, muts: [] }), updatedDocs[documentId].after = res.after);
  }
  return Object.entries(updatedDocs).map(
    // eslint-disable-next-line no-shadow
    ([id, { before, after, muts }]) => ({
      id,
      status: after ? before ? "updated" : "created" : "deleted",
      mutations: muts,
      before,
      after
    })
  );
}
function commit(results, dataset) {
  results.forEach((result) => {
    (result.status === "created" || result.status === "updated") && dataset.set(result.id, result.after), result.status === "deleted" && dataset.delete(result.id);
  });
}
function takeUntilRight(arr, predicate, opts) {
  const result = [];
  for (const item of arr.slice().reverse()) {
    if (predicate(item))
      return result;
    result.push(item);
  }
  return result.reverse();
}
function isEqualPath(p1, p2) {
  return stringify(p1) === stringify(p2);
}
function supersedes(later, earlier) {
  return (earlier.type === "set" || earlier.type === "unset") && (later.type === "set" || later.type === "unset");
}
function squashNodePatches(patches) {
  return compactSetIfMissingPatches(
    compactSetPatches(compactUnsetPatches(patches))
  );
}
function compactUnsetPatches(patches) {
  return patches.reduce(
    (earlierPatches, laterPatch) => {
      if (laterPatch.op.type !== "unset")
        return earlierPatches.push(laterPatch), earlierPatches;
      const unaffected = earlierPatches.filter(
        (earlierPatch) => !startsWith(laterPatch.path, earlierPatch.path)
      );
      return unaffected.push(laterPatch), unaffected;
    },
    []
  );
}
function compactSetPatches(patches) {
  return patches.reduceRight(
    (laterPatches, earlierPatch) => (laterPatches.find(
      (later) => supersedes(later.op, earlierPatch.op) && isEqualPath(later.path, earlierPatch.path)
    ) || laterPatches.unshift(earlierPatch), laterPatches),
    []
  );
}
function compactSetIfMissingPatches(patches) {
  return patches.reduce(
    (previousPatches, laterPatch) => laterPatch.op.type !== "setIfMissing" ? (previousPatches.push(laterPatch), previousPatches) : (takeUntilRight(
      previousPatches,
      (patch2) => patch2.op.type === "unset"
    ).find(
      (precedingPatch) => precedingPatch.op.type === "setIfMissing" && isEqualPath(precedingPatch.path, laterPatch.path)
    ) || previousPatches.push(laterPatch), previousPatches),
    []
  );
}
function compactDMPSetPatches(base, patches) {
  let edge = base;
  return patches.reduce(
    (earlierPatches, laterPatch) => {
      const before = edge;
      if (edge = applyNodePatch(laterPatch, edge), laterPatch.op.type === "set" && typeof laterPatch.op.value == "string") {
        const current = getAtPath(laterPatch.path, before);
        if (typeof current == "string") {
          const replaced = {
            ...laterPatch,
            op: {
              type: "diffMatchPatch",
              value: diffMatchPatch$1.stringifyPatches(
                diffMatchPatch$1.makePatches(current, laterPatch.op.value)
              )
            }
          };
          return earlierPatches.flatMap((ep) => isEqualPath(ep.path, laterPatch.path) && ep.op.type === "diffMatchPatch" ? [] : ep).concat(replaced);
        }
      }
      return earlierPatches.push(laterPatch), earlierPatches;
    },
    []
  );
}
function squashDMPStrings(remote, mutationGroups) {
  return mutationGroups.map((mutationGroup) => ({
    ...mutationGroup,
    mutations: dmpIfyMutations(remote, mutationGroup.mutations)
  }));
}
function dmpIfyMutations(store, mutations) {
  return mutations.map((mutation, i) => mutation.type === "patch" ? dmpifyPatchMutation(store.get(mutation.id), mutation) : mutation);
}
function dmpifyPatchMutation(base, mutation) {
  return base ? {
    ...mutation,
    patches: compactDMPSetPatches(base, mutation.patches)
  } : mutation;
}
function mergeMutationGroups(mutationGroups) {
  return chunkWhile(mutationGroups, (group) => !group.transaction).flatMap(
    (chunk) => ({
      ...chunk[0],
      mutations: chunk.flatMap((c) => c.mutations)
    })
  );
}
function chunkWhile(arr, predicate) {
  const res = [];
  let currentChunk = [];
  return arr.forEach((item) => {
    predicate(item) ? currentChunk.push(item) : (currentChunk.length > 0 && res.push(currentChunk), currentChunk = [], res.push([item]));
  }), currentChunk.length > 0 && res.push(currentChunk), res;
}
function squashMutationGroups(staged) {
  return mergeMutationGroups(staged).map((transaction) => ({
    ...transaction,
    mutations: squashMutations(transaction.mutations)
  })).map((transaction) => ({
    ...transaction,
    mutations: transaction.mutations.map((mutation) => mutation.type !== "patch" ? mutation : {
      ...mutation,
      patches: squashNodePatches(mutation.patches)
    })
  }));
}
function squashMutations(mutations) {
  const byDocument = groupBy__default.default(mutations, getMutationDocumentId);
  return Object.values(byDocument).flatMap((documentMutations) => squashCreateIfNotExists(squashDelete(documentMutations)).flat().reduce((acc, docMutation) => {
    const prev = acc[acc.length - 1];
    return (!prev || prev.type === "patch") && docMutation.type === "patch" ? acc.slice(0, -1).concat({
      ...docMutation,
      patches: (prev?.patches || []).concat(docMutation.patches)
    }) : acc.concat(docMutation);
  }, []));
}
function squashCreateIfNotExists(mutations) {
  return mutations.length === 0 ? mutations : mutations.reduce((previousMuts, laterMut) => laterMut.type !== "createIfNotExists" ? (previousMuts.push(laterMut), previousMuts) : (takeUntilRight(previousMuts, (m) => m.type === "delete").find(
    (precedingPatch) => precedingPatch.type === "createIfNotExists"
  ) || previousMuts.push(laterMut), previousMuts), []);
}
function squashDelete(mutations) {
  return mutations.length === 0 ? mutations : mutations.reduce((previousMuts, laterMut) => laterMut.type === "delete" ? [laterMut] : (previousMuts.push(laterMut), previousMuts), []);
}
function rebase(documentId, oldBase, newBase, stagedMutations) {
  let edge = oldBase;
  const dmpified = stagedMutations.map((transaction) => {
    const mutations = transaction.mutations.flatMap((mut) => {
      if (getMutationDocumentId(mut) !== documentId)
        return [];
      const before = edge;
      return edge = applyAll(edge, [mut]), !before || mut.type !== "patch" ? mut : {
        type: "dmpified",
        mutation: {
          ...mut,
          // Todo: make compactDMPSetPatches return pairs of patches that was dmpified with their
          //  original as dmpPatches and original is not 1:1 (e..g some of the original may not be dmpified)
          dmpPatches: compactDMPSetPatches(before, mut.patches),
          original: mut.patches
        }
      };
    });
    return { ...transaction, mutations };
  });
  let newBaseWithDMPForOldBaseApplied = newBase;
  return dmpified.map((transaction) => {
    const applied = [];
    return transaction.mutations.forEach((mut) => {
      if (mut.type === "dmpified")
        try {
          newBaseWithDMPForOldBaseApplied = applyPatches(
            mut.mutation.dmpPatches,
            newBaseWithDMPForOldBaseApplied
          ), applied.push(mut);
        } catch {
          console.warn("Failed to apply dmp patch, falling back to original");
          try {
            newBaseWithDMPForOldBaseApplied = applyPatches(
              mut.mutation.original,
              newBaseWithDMPForOldBaseApplied
            ), applied.push(mut);
          } catch (second) {
            throw new Error(
              `Failed to apply patch for document "${documentId}": ${second.message}`
            );
          }
        }
      else
        newBaseWithDMPForOldBaseApplied = applyAll(
          newBaseWithDMPForOldBaseApplied,
          [mut]
        );
    });
  }), [stagedMutations.map((transaction) => ({
    ...transaction,
    mutations: transaction.mutations.map((mut) => mut.type !== "patch" || getMutationDocumentId(mut) !== documentId ? mut : {
      ...mut,
      patches: mut.patches.map((patch2) => patch2.op.type !== "set" ? patch2 : {
        ...patch2,
        op: {
          ...patch2.op,
          value: getAtPath(patch2.path, newBaseWithDMPForOldBaseApplied)
        }
      })
    })
  })), newBaseWithDMPForOldBaseApplied];
}
function toTransactions(groups) {
  return groups.map((group) => group.transaction && group.id !== void 0 ? { id: group.id, mutations: group.mutations } : { mutations: group.mutations });
}
function encode(mutation) {
  return encodeMutation(mutation);
}
function encodeAll(mutations) {
  return mutations.flatMap(encode);
}
function encodeTransaction(transaction) {
  return {
    transactionId: transaction.id,
    mutations: encodeAll(transaction.mutations)
  };
}
function encodeMutation(mutation) {
  if (mutation.type === "create" || mutation.type === "createIfNotExists" || mutation.type === "createOrReplace")
    return { [mutation.type]: mutation.document };
  if (mutation.type === "delete")
    return {
      delete: { id: mutation.id }
    };
  const ifRevisionID = mutation.options?.ifRevision;
  return mutation.patches.map((patch2) => ({
    patch: {
      id: mutation.id,
      ...ifRevisionID && { ifRevisionID },
      ...patchToSanity(patch2)
    }
  }));
}
function patchToSanity(patch2) {
  const { path, op } = patch2;
  if (op.type === "unset")
    return { unset: [stringify(path)] };
  if (op.type === "insert")
    return {
      insert: {
        [op.position]: stringify([...path, op.referenceItem]),
        items: op.items
      }
    };
  if (op.type === "diffMatchPatch")
    return { diffMatchPatch: { [stringify(path)]: op.value } };
  if (op.type === "inc")
    return { inc: { [stringify(path)]: op.amount } };
  if (op.type === "dec")
    return { dec: { [stringify(path)]: op.amount } };
  if (op.type === "set" || op.type === "setIfMissing")
    return { [op.type]: { [stringify(path)]: op.value } };
  if (op.type === "truncate") {
    const range = [
      op.startIndex,
      typeof op.endIndex == "number" ? op.endIndex : ""
    ].join(":");
    return { unset: [`${stringify(path)}[${range}]`] };
  }
  if (op.type === "upsert")
    return {
      unset: op.items.map(
        (item) => stringify([...path, { _key: item._key }])
      ),
      insert: {
        [op.position]: stringify([...path, op.referenceItem]),
        items: op.items
      }
    };
  if (op.type === "assign")
    return {
      set: Object.fromEntries(
        Object.keys(op.value).map((key) => [
          stringify(path.concat(key)),
          op.value[key]
        ])
      )
    };
  if (op.type === "unassign")
    return {
      unset: op.keys.map((key) => stringify(path.concat(key)))
    };
  if (op.type === "replace")
    return {
      insert: {
        replace: stringify(path.concat(op.referenceItem)),
        items: op.items
      }
    };
  if (op.type === "remove")
    return {
      unset: [stringify(path.concat(op.referenceItem))]
    };
  throw new Error(`Unknown operation type ${op.type}`);
}
function createSharedListener(client) {
  const allEvents$ = client.listen(
    '*[!(_id in path("_.**"))]',
    {},
    {
      events: ["welcome", "mutation", "reconnect"],
      includeResult: !1,
      includePreviousRevision: !1,
      visibility: "transaction",
      effectFormat: "mendoza",
      includeMutations: !1
    }
  ).pipe(rxjs.share({ resetOnRefCountZero: !0 })), reconnect = allEvents$.pipe(
    rxjs.filter((event) => event.type === "reconnect")
  ), welcome = allEvents$.pipe(
    rxjs.filter((event) => event.type === "welcome")
  ), mutations = allEvents$.pipe(
    rxjs.filter((event) => event.type === "mutation")
  ), replayWelcome = rxjs.merge(welcome, reconnect).pipe(
    rxjs.shareReplay({ bufferSize: 1, refCount: !0 })
  ).pipe(
    rxjs.filter((latestConnectionEvent) => latestConnectionEvent.type === "welcome")
  );
  return rxjs.merge(replayWelcome, mutations, reconnect);
}
const documentMutatorMachine = xstate.setup({
  types: {},
  actions: {
    "assign error to context": xstate.assign({ error: ({ event }) => event }),
    "clear error from context": xstate.assign({ error: void 0 }),
    "connect to server-sent events": xstate.raise({ type: "connect" }),
    "listen to server-sent events": xstate.spawnChild("server-sent events", {
      id: "listener",
      input: ({ context }) => ({
        listener: context.sharedListener || createSharedListener(context.client),
        id: context.id
      })
    }),
    "stop listening to server-sent events": xstate.stopChild("listener"),
    "buffer remote mutation events": xstate.assign({
      mutationEvents: ({ event, context }) => (xstate.assertEvent(event, "mutation"), [...context.mutationEvents, event])
    }),
    "restore stashed changes": xstate.assign({
      stagedChanges: ({ event, context }) => (xstate.assertEvent(event, "xstate.done.actor.submitTransactions"), context.stashedChanges),
      stashedChanges: []
    }),
    "rebase fetched remote snapshot": xstate.enqueueActions(({ enqueue }) => {
      enqueue.assign(({ event, context }) => {
        xstate.assertEvent(event, "xstate.done.actor.getDocument");
        const previousRemote = context.remote;
        let nextRemote = event.output, seenCurrentRev = !1;
        for (const patch2 of context.mutationEvents)
          !patch2.effects?.apply || !patch2.previousRev && patch2.transition !== "appear" || (!seenCurrentRev && patch2.previousRev === nextRemote?._rev && (seenCurrentRev = !0), seenCurrentRev && (nextRemote = applyMendozaPatch(
            nextRemote,
            patch2.effects.apply,
            patch2.resultRev
          )));
        context.cache && // If the shared cache don't have the document already we can just set it
        (!context.cache.has(context.id) || // But when it's in the cache, make sure it's necessary to update it
        context.cache.get(context.id)._rev !== nextRemote?._rev) && context.cache.set(context.id, nextRemote);
        const [stagedChanges, local] = rebase(
          context.id,
          // It's annoying to convert between null and undefined, reach consensus
          previousRemote === null ? void 0 : previousRemote,
          nextRemote === null ? void 0 : nextRemote,
          context.stagedChanges
        );
        return {
          remote: nextRemote,
          local,
          stagedChanges,
          // Since the snapshot handler applies all the patches they are no longer needed, allow GC
          mutationEvents: []
        };
      }), enqueue.sendParent(
        ({ context }) => ({
          type: "rebased.remote",
          id: context.id,
          document: context.remote
        })
      );
    }),
    "apply mendoza patch": xstate.assign(({ event, context }) => {
      xstate.assertEvent(event, "mutation");
      const previousRemote = context.remote;
      if (event.transactionId === previousRemote?._rev)
        return {};
      const nextRemote = applyMendozaPatch(
        previousRemote,
        event.effects.apply,
        event.resultRev
      );
      context.cache && // If the shared cache don't have the document already we can just set it
      (!context.cache.has(context.id) || // But when it's in the cache, make sure it's necessary to update it
      context.cache.get(context.id)._rev !== nextRemote?._rev) && context.cache.set(context.id, nextRemote);
      const [stagedChanges, local] = rebase(
        context.id,
        // It's annoying to convert between null and undefined, reach consensus
        previousRemote === null ? void 0 : previousRemote,
        nextRemote === null ? void 0 : nextRemote,
        context.stagedChanges
      );
      return {
        remote: nextRemote,
        local,
        stagedChanges
      };
    }),
    "increment fetch attempts": xstate.assign({
      fetchRemoteSnapshotAttempts: ({ context }) => context.fetchRemoteSnapshotAttempts + 1
    }),
    "reset fetch attempts": xstate.assign({
      fetchRemoteSnapshotAttempts: 0
    }),
    "increment submit attempts": xstate.assign({
      submitTransactionsAttempts: ({ context }) => context.submitTransactionsAttempts + 1
    }),
    "reset submit attempts": xstate.assign({
      submitTransactionsAttempts: 0
    }),
    "stage mutation": xstate.assign({
      stagedChanges: ({ event, context }) => (xstate.assertEvent(event, "mutate"), [
        ...context.stagedChanges,
        { transaction: !1, mutations: event.mutations }
      ])
    }),
    "stash mutation": xstate.assign({
      stashedChanges: ({ event, context }) => (xstate.assertEvent(event, "mutate"), [
        ...context.stashedChanges,
        { transaction: !1, mutations: event.mutations }
      ])
    }),
    "rebase local snapshot": xstate.enqueueActions(({ enqueue }) => {
      enqueue.assign({
        local: ({ event, context }) => {
          xstate.assertEvent(event, "mutate");
          const localDataset = /* @__PURE__ */ new Map();
          context.local && localDataset.set(context.id, context.local);
          const results = applyMutations(event.mutations, localDataset);
          return commit(results, localDataset), localDataset.get(context.id);
        }
      }), enqueue.sendParent(
        ({ context }) => ({
          type: "rebased.local",
          id: context.id,
          document: context.local
        })
      );
    }),
    "send pristine event to parent": xstate.sendParent(
      ({ context }) => ({
        type: "pristine",
        id: context.id
      })
    ),
    "send sync event to parent": xstate.sendParent(
      ({ context }) => ({
        type: "sync",
        id: context.id,
        document: context.remote
      })
    ),
    "send mutation event to parent": xstate.sendParent(({ context, event }) => (xstate.assertEvent(event, "mutation"), {
      type: "mutation",
      id: context.id,
      previousRev: event.previousRev,
      resultRev: event.resultRev,
      effects: event.effects
    }))
  },
  actors: {
    "server-sent events": xstate.fromEventObservable(
      ({
        input
      }) => {
        const { listener, id } = input;
        return rxjs.defer(() => listener).pipe(
          rxjs.filter(
            (event) => event.type === "welcome" || event.type === "reconnect" || event.type === "mutation" && event.documentId === id
          ),
          // This is necessary to avoid sync emitted events from `shareReplay` from happening before the actor is ready to receive them
          rxjs.observeOn(rxjs.asapScheduler)
        );
      }
    ),
    "fetch remote snapshot": xstate.fromPromise(
      async ({
        input,
        signal
      }) => {
        const { client, id } = input;
        return await client.getDocument(id, {
          signal
        }).catch((e) => {
          if (!(e instanceof Error && e.name === "AbortError"))
            throw e;
        });
      }
    ),
    "submit mutations as transactions": xstate.fromPromise(
      async ({
        input,
        signal
      }) => {
        const { client, transactions } = input;
        for (const transaction of transactions) {
          if (signal.aborted) return;
          await client.dataRequest("mutate", encodeTransaction(transaction), {
            visibility: "async",
            returnDocuments: !1,
            signal
          }).catch((e) => {
            if (!(e instanceof Error && e.name === "AbortError"))
              throw e;
          });
        }
      }
    )
  },
  delays: {
    // Exponential backoff delay function
    fetchRemoteSnapshotTimeout: ({ context }) => Math.pow(2, context.fetchRemoteSnapshotAttempts) * 1e3,
    submitTransactionsTimeout: ({ context }) => Math.pow(2, context.submitTransactionsAttempts) * 1e3
  }
}).createMachine({
  /** @xstate-layout N4IgpgJg5mDOIC5QQPYGMCuBbMA7ALgLRYb4CG+KATgMQnn5gDaADALqKgAOKsAlvj4pcnEAA9EADhYAWAHQA2GSwUBmAKwBOaQEZJkhQBoQAT0Q6ATAF8rx1JhwFipCtTkQ+sNMNxg0jCBpvXF9-Vg4kEB5+QWFRCQQLFhY5PQB2dRU1SQsdGSVjMwRlHTkWNM00nR1VKryKmzt0bDwielcqOWDQwVwoGgB3MAAbbxxw0WiBIRFIhPUKuQ1NVU0tTU0WFdVCxAt1dTlNhX2WdRltGUk061sQexandspO7r9e-qo-H3eJyKnYrNQPNJJollpVutNttdghVCo5MoTgoMpo8jIkqpGvdmo42i4Xl0fv4+H0aGAqFRqH9uLxpnE5ogFrCLFd5CtNBYFJkdOpuaosXcHnjnAw3G9-AAxMh8YYYL5BYn4GlROmA+KIFEs1R6ORpZYWHIXGR6bHC1qijpyL4Sj6DEZjZjsSZqmYaxK1ORcvlc-ZqSoyNKwnRpGTyK4WDK5BQ6BQ5BRm3EW55uG1K0n9ClUqgqgFuxketJe7nIv2rUNB0x7LmSL2qGMsSySevcmSJhzJgnipWQOgEma510M4HmcqHZYyWqaOMqTQyWGh0osVSGiwC5uGyftx74sWvHuBNMhX7O-5DoHiPae72lvnlwPBydFlRVS7qPIl7cilP74-+SByMMKBkB4ZKoL4cikgAbigADWYByDA+AACJJgQg4xPmI7FHkZQrKGsjqKcCiaMG9YpJOxySBiCiyPoX6dnuRJ-gEgHAaBmaUm4XDDBQABm1BYIhYAoWhyqnrSmHDpeCAKCicjUbU6g6nkFichYsJrLWVxaPsk7KdICZCmJlqEraAFASBvbPAOEmqlJF4JJURbVDcy4Yvk1GVkUsabApMjKZGqjNg2kgMU8Xa-j0FnsQBXBUJ4vRgH2DBOhEkn0o5TLKV6y6WDG6lhkYVYIDoKzyBkeR8pUDZqOFu5WuZEBsVZzUeFQ+AmDQsAYAARlgAgYZl7o6I2tYLJINSSO+3JaMGlQpGkhFhryo2jW2xkdhFTFNS1EAAT1-UCHa4EIdBcEIYdA34AAKlQZC4LAZAksIsBDeqBbrdpym8iuByxlcLK5BYqQLBUZyTcFvL1aZ3YsTFrVyFdx0ZuSXGdDx-GCUjfXXXdD1PS9j3vVhMnrWCFRxtNaRLdcfIsiwuS5fkgZaOUlhpDDP7MdFzWWftzXI-gdrPGlLoOSNyiHFstRySisjcgzahyFoUYBbRsac5tO6w1F7wIwLONHfg0qyvKyVfPgVAmCT0kJGt41pJD02xgcpElUkcZ6rI+q5JcckbU0W0NWZB57QduMCKbcoKmIsCpXIZB8YwVAABRC-jj3PYCsA3XwOAoKQACUNDmttjVh-zEfG9H5u21lpVjSrTtTTNbsstUYJJAFWgA37XORTz+t8+xtcKpb1v1+6KJFopGQqRi6nBlstYcqNK5riusYDztlejzKMfJXHCdJynqd8SJaAABYAEpgFgKCMAAyrgZBcLAV+P3nBfF6XJnc7tfmY8xZnglgWGe-klILzUhYDSJVRpnCONNOcWxWRKBRDYO4uAUD7XgJEMuIdqDi2GgWQgOhgxMyRKyFc8IuQkXUDvK0HgvAHmIR9bCD4SoeSWCoLkoZpxrmXIw0OLEMxsNJgkSc418KhnrHyG4oZYTcPhMifhJx4SCiDjrABSpgHiLtogAUhwW77DRIGXkk55wexKCrJQsg1jBTnPsYRqZviiL6PohuORgyhhBhGKMsZYzxhcXrf8EBPHulUJOPCtRlABWIu7IoORVBIIhMpNYGJyghKHmEvaYjQEkOwhkxQrJtBES0JDOBPlkgKD1JYZSjZORyTXNkwBsVwkFPYTJVYS58JxPKbOYM0gUj7FjGcEMOpciaJxMHXWOTWJV2avFRKpIwARILJRGJBF4mZBIkDE0KtIxLSSDkDYGhWl70Ru1Tq6zsLURBkoLyWRmz8PmlUZmcY1zXDKdMghcy2mIyFh8W5ZN4RFmOFyKaZwiLeT2GVJcy5pBrguCiMK2tvyDwBYbIWejOkSMQBkeQORJq0RNCUDIDNondxuGpPQmRqIXPhiPECuKMpdMkbILZ-SEnLxyjqOJMZsj1jRTYIAA */
  id: "document-mutator",
  context: ({ input }) => ({
    client: input.client.withConfig({ allowReconfigure: !1 }),
    sharedListener: input.sharedListener,
    id: input.id,
    remote: void 0,
    local: void 0,
    mutationEvents: [],
    stagedChanges: [],
    stashedChanges: [],
    error: void 0,
    fetchRemoteSnapshotAttempts: 0,
    submitTransactionsAttempts: 0,
    cache: input.cache
  }),
  // Auto start the connection by default
  entry: ["connect to server-sent events"],
  on: {
    mutate: {
      actions: ["rebase local snapshot", "stage mutation"]
    }
  },
  initial: "disconnected",
  states: {
    disconnected: {
      on: {
        connect: {
          target: "connecting",
          actions: ["listen to server-sent events"]
        }
      }
    },
    connecting: {
      on: {
        welcome: "connected",
        reconnect: "reconnecting",
        error: "connectFailure"
      },
      tags: ["busy"]
    },
    connectFailure: {
      on: {
        connect: {
          target: "connecting",
          actions: ["listen to server-sent events"]
        }
      },
      entry: [
        "stop listening to server-sent events",
        "assign error to context"
      ],
      exit: ["clear error from context"],
      tags: ["error"]
    },
    reconnecting: {
      on: {
        welcome: {
          target: "connected"
        },
        error: {
          target: "connectFailure"
        }
      },
      tags: ["busy", "error"]
    },
    connected: {
      on: {
        mutation: {
          actions: ["buffer remote mutation events"]
        },
        reconnect: "reconnecting"
      },
      entry: ["clear error from context"],
      initial: "loading",
      states: {
        loading: {
          invoke: {
            src: "fetch remote snapshot",
            id: "getDocument",
            input: ({ context }) => ({
              client: context.client,
              id: context.id
            }),
            onError: {
              target: "loadFailure"
            },
            onDone: {
              target: "loaded",
              actions: [
                "rebase fetched remote snapshot",
                "reset fetch attempts"
              ]
            }
          },
          tags: ["busy"]
        },
        loaded: {
          entry: ["send sync event to parent"],
          on: {
            mutation: {
              actions: ["apply mendoza patch", "send mutation event to parent"]
            }
          },
          initial: "pristine",
          states: {
            pristine: {
              on: {
                mutate: {
                  actions: ["rebase local snapshot", "stage mutation"],
                  target: "dirty"
                }
              },
              tags: ["ready"]
            },
            dirty: {
              on: {
                submit: "submitting"
              },
              tags: ["ready"]
            },
            submitting: {
              on: {
                mutate: {
                  actions: ["rebase local snapshot", "stash mutation"]
                }
              },
              invoke: {
                src: "submit mutations as transactions",
                id: "submitTransactions",
                input: ({ context }) => {
                  const remoteDataset = /* @__PURE__ */ new Map();
                  return remoteDataset.set(context.id, context.remote), {
                    client: context.client,
                    transactions: toTransactions(
                      // Squashing DMP strings is the last thing we do before submitting
                      squashDMPStrings(
                        remoteDataset,
                        squashMutationGroups(context.stagedChanges)
                      )
                    )
                  };
                },
                onError: {
                  target: "submitFailure"
                },
                onDone: {
                  target: "pristine",
                  actions: [
                    "restore stashed changes",
                    "reset submit attempts",
                    "send pristine event to parent"
                  ]
                }
              },
              /**
               * 'busy' means we should show a spinner, 'ready' means we can still accept mutations, they'll be applied optimistically right away, and queued for submissions after the current submission settles
               */
              tags: ["busy", "ready"]
            },
            submitFailure: {
              exit: ["clear error from context"],
              after: {
                submitTransactionsTimeout: {
                  actions: ["increment submit attempts"],
                  target: "submitting"
                }
              },
              on: {
                retry: "submitting"
              },
              /**
               * How can it be both `ready` and `error`? `ready` means it can receive mutations, optimistically apply them, and queue them for submission. `error` means it failed to submit previously applied mutations.
               * It's completely fine to keep queueing up more mutations and applying them optimistically, while showing UI that notifies that mutations didn't submit, and show a count down until the next automatic retry.
               */
              tags: ["error", "ready"]
            }
          }
        },
        loadFailure: {
          exit: ["clear error from context"],
          after: {
            fetchRemoteSnapshotTimeout: {
              actions: ["increment fetch attempts"],
              target: "loading"
            }
          },
          on: {
            retry: "loading"
          },
          tags: ["error"]
        }
      }
    }
  }
});
function applyMendozaPatch(document, patch2, nextRevision) {
  const next = mendoza.applyPatch(omitRev(document), patch2);
  return next ? Object.assign(next, { _rev: nextRevision }) : null;
}
function omitRev(document) {
  if (!document)
    return null;
  const { _rev, ...doc } = document;
  return doc;
}
exports.applyMutations = applyMutations;
exports.commit = commit;
exports.createSharedListener = createSharedListener;
exports.documentMutatorMachine = documentMutatorMachine;
exports.rebase = rebase;
exports.squashDMPStrings = squashDMPStrings;
exports.squashMutationGroups = squashMutationGroups;
exports.toTransactions = toTransactions;
//# sourceMappingURL=_unstable_machine.browser.cjs.map
