{"version":3,"file":"_unstable_machine.browser.js","sources":["../src/store/utils/getMutationDocumentId.ts","../node_modules/.pnpm/nanoid@5.0.8/node_modules/nanoid/url-alphabet/index.js","../node_modules/.pnpm/nanoid@5.0.8/node_modules/nanoid/index.browser.js","../src/path/utils/predicates.ts","../src/path/get/getAtPath.ts","../src/path/parser/stringify.ts","../src/utils/isObject.ts","../src/apply/utils/getKeyOf.ts","../src/apply/utils/array.ts","../src/apply/patch/operations/array.ts","../src/apply/patch/operations/common.ts","../src/apply/patch/operations/number.ts","../src/apply/utils/hasOwn.ts","../src/apply/utils/isEmpty.ts","../src/apply/utils/omit.ts","../src/apply/patch/operations/object.ts","../src/apply/patch/operations/string.ts","../src/apply/patch/applyOp.ts","../src/apply/patch/applyNodePatch.ts","../src/apply/applyPatchMutation.ts","../src/apply/store/utils.ts","../src/store/datasets/applyDocumentMutation.ts","../src/store/datasets/applyMutations.ts","../src/store/datasets/commit.ts","../src/store/utils/arrayUtils.ts","../src/store/optimizations/squashNodePatches.ts","../src/store/optimizations/squashDMPStrings.ts","../src/store/utils/mergeMutationGroups.ts","../src/store/optimizations/squashMutations.ts","../src/store/rebase.ts","../src/store/toTransactions.ts","../src/encoders/sanity/encode.ts","../src/machine/listener.ts","../src/machine/documentMutatorMachine.ts"],"sourcesContent":["type MutationLike =\n  | {type: 'patch'; id: string}\n  | {type: 'create'; document: {_id: string}}\n  | {type: 'delete'; id: string}\n  | {type: 'createIfNotExists'; document: {_id: string}}\n  | {type: 'createOrReplace'; document: {_id: string}}\n\nexport function getMutationDocumentId(mutation: MutationLike): string {\n  if (mutation.type === 'patch') {\n    return mutation.id\n  }\n  if (mutation.type === 'create') {\n    return mutation.document._id\n  }\n  if (mutation.type === 'delete') {\n    return mutation.id\n  }\n  if (mutation.type === 'createIfNotExists') {\n    return mutation.document._id\n  }\n  if (mutation.type === 'createOrReplace') {\n    return mutation.document._id\n  }\n  throw new Error('Invalid mutation type')\n}\n","export const urlAlphabet =\n  'useandom-26T198340PX75pxJACKVERYMINDBUSHWOLF_GQZbfghjklqvwyzrict'\n","import { urlAlphabet as scopedUrlAlphabet } from './url-alphabet/index.js'\nexport { urlAlphabet } from './url-alphabet/index.js'\nexport let random = bytes => crypto.getRandomValues(new Uint8Array(bytes))\nexport let customRandom = (alphabet, defaultSize, getRandom) => {\n  let mask = (2 << Math.log2(alphabet.length - 1)) - 1\n  let step = -~((1.6 * mask * defaultSize) / alphabet.length)\n  return (size = defaultSize) => {\n    let id = ''\n    while (true) {\n      let bytes = getRandom(step)\n      let j = step\n      while (j--) {\n        id += alphabet[bytes[j] & mask] || ''\n        if (id.length === size) return id\n      }\n    }\n  }\n}\nexport let customAlphabet = (alphabet, size = 21) =>\n  customRandom(alphabet, size, random)\nexport let nanoid = (size = 21) => {\n  let id = ''\n  let bytes = crypto.getRandomValues(new Uint8Array(size))\n  while (size--) {\n    id += scopedUrlAlphabet[bytes[size] & 63]\n  }\n  return id\n}\n","import {type KeyedPathElement, type Path, type PathElement} from '../types'\n\nfunction safeGetElementAt<T>(array: T[] | readonly T[], index: number): T {\n  if (index < 0 || index >= array.length) {\n    throw new Error('Index out of bounds')\n  }\n  return array[index]!\n}\n\nexport function startsWith(parentPath: Path, path: Path): boolean {\n  return (\n    parentPath.length <= path.length &&\n    parentPath.every((segment, i) =>\n      isElementEqual(segment, safeGetElementAt(path, i)),\n    )\n  )\n}\n\nexport function isEqual(path: Path, otherPath: Path): boolean {\n  return (\n    path.length === otherPath.length &&\n    path.every((segment, i) =>\n      isElementEqual(segment, safeGetElementAt(path, i)),\n    )\n  )\n}\n\nexport function isElementEqual(\n  segmentA: PathElement,\n  segmentB: PathElement,\n): boolean {\n  if (isKeyElement(segmentA) && isKeyElement(segmentB)) {\n    return segmentA._key === segmentB._key\n  }\n\n  if (isIndexElement(segmentA)) {\n    return Number(segmentA) === Number(segmentB)\n  }\n\n  return segmentA === segmentB\n}\n\nexport function isKeyElement(\n  segment: PathElement,\n): segment is KeyedPathElement {\n  return typeof (segment as any)?._key === 'string'\n}\nexport function isIndexElement(segment: PathElement): segment is number {\n  return typeof segment === 'number'\n}\n\nexport function isKeyedElement(\n  element: PathElement,\n): element is KeyedPathElement {\n  return (\n    typeof element === 'object' &&\n    '_key' in element &&\n    typeof element._key === 'string'\n  )\n}\nexport function isArrayElement(\n  element: PathElement,\n): element is KeyedPathElement | number {\n  return typeof element === 'number' || isKeyedElement(element)\n}\n\nexport function isPropertyElement(element: PathElement): element is string {\n  return typeof element === 'string'\n}\n","import {type AnyArray} from '../../utils/typeUtils'\nimport {type KeyedPathElement, type Path, type PathElement} from '../types'\nimport {isArrayElement, isKeyedElement} from '../utils/predicates'\nimport {type FindInArray} from './types'\n\nexport type {AnyArray} from '../../utils/typeUtils'\n\nexport type Get<\n  P extends number | KeyedPathElement | Readonly<KeyedPathElement> | string,\n  T,\n> = T extends AnyArray\n  ? P extends KeyedPathElement | Readonly<KeyedPathElement> | number\n    ? FindInArray<P, T>\n    : undefined\n  : P extends keyof T\n    ? T[P]\n    : never\n\nexport type GetAtPath<P extends readonly PathElement[], T> = P extends []\n  ? T\n  : P extends [infer Head, ...infer Tail]\n    ? Head extends PathElement\n      ? Tail extends PathElement[]\n        ? GetAtPath<Tail, Get<Head, T>>\n        : undefined\n      : undefined\n    : undefined\n\nexport function getAtPath<const Head extends PathElement, const T>(\n  path: [head: Head],\n  value: T,\n): Get<Head, T>\nexport function getAtPath<\n  const Head extends PathElement,\n  const Tail extends PathElement[],\n  T,\n>(path: [head: Head, ...tail: Tail], value: T): GetAtPath<[Head, ...Tail], T>\nexport function getAtPath<T>(path: [], value: T): T\nexport function getAtPath(path: Path, value: unknown): unknown\nexport function getAtPath(path: Path, value: unknown): unknown {\n  if (path.length === 0) {\n    return value\n  }\n\n  let current = value\n  for (const head of path) {\n    if (isArrayElement(head)) {\n      if (!Array.isArray(current)) {\n        return undefined\n      }\n\n      if (isKeyedElement(head)) {\n        current = current.find(item => item._key === head._key)\n        continue\n      }\n      current = current[head]\n      continue\n    }\n    current = (current as any)[head]\n  }\n  return current\n}\n","import {type Path, type PathElement} from '../types'\nimport {isKeyedElement} from '../utils/predicates'\n\nconst IS_DOTTABLE = /^[a-z_$]+/\n\nfunction stringifySegment(segment: PathElement, hasLeading: boolean): string {\n  if (Array.isArray(segment)) {\n    return `[${segment[0]}:${segment[1] || ''}]`\n  }\n  const type = typeof segment\n\n  const isNumber = type === 'number'\n\n  if (isNumber) {\n    return `[${segment}]`\n  }\n\n  if (isKeyedElement(segment)) {\n    return `[_key==${JSON.stringify(segment._key)}]`\n  }\n\n  if (typeof segment === 'string' && IS_DOTTABLE.test(segment)) {\n    return hasLeading ? segment : `.${segment}`\n  }\n\n  return `['${segment}']`\n}\n\nexport function stringify(pathArray: Path): string {\n  return pathArray\n    .map((segment, i) => stringifySegment(segment, i === 0))\n    .join('')\n}\n","export function isObject(val: unknown): val is {\n  [K in string]: unknown\n} {\n  return val !== null && typeof val === 'object' && !Array.isArray(val)\n}\n","export function keyOf(value: any): string | null {\n  return (\n    (value !== null &&\n      typeof value === 'object' &&\n      typeof value._key === 'string' &&\n      value._key) ||\n    null\n  )\n}\n","import {isKeyedElement, type PathElement} from '../../path'\nimport {keyOf} from './getKeyOf'\n\nexport function findTargetIndex<T>(array: T[], pathSegment: PathElement) {\n  if (typeof pathSegment === 'number') {\n    return normalizeIndex(array.length, pathSegment)\n  }\n  if (isKeyedElement(pathSegment)) {\n    const idx = array.findIndex(value => keyOf(value) === pathSegment._key)\n    return idx === -1 ? null : idx\n  }\n  throw new Error(\n    `Expected path segment to be addressing a single array item either by numeric index or by '_key'. Instead saw ${JSON.stringify(\n      pathSegment,\n    )}`,\n  )\n}\n\nexport function getTargetIdx(position: 'before' | 'after', index: number) {\n  return position === 'before' ? index : index + 1\n}\n\n// normalizes the index according to the array length\n// returns null if the normalized index is out of bounds\nexport function normalizeIndex(length: number, index: number) {\n  if (length === 0 && (index === -1 || index === 0)) {\n    return 0\n  }\n  const normalized = index < 0 ? length + index : index\n  return normalized >= length || normalized < 0 ? null : normalized\n}\n\n// non-mutating splice\nexport function splice<T>(arr: T[], start: number, deleteCount: number): T[]\nexport function splice<T>(\n  arr: T[],\n  start: number,\n  deleteCount: number,\n  items: T[],\n): T[]\nexport function splice<T>(\n  arr: T[],\n  start: number,\n  deleteCount: number,\n  items?: T[],\n): T[] {\n  const copy = arr.slice()\n  copy.splice(start, deleteCount, ...(items || []))\n  return copy\n}\n","import {\n  type InsertOp,\n  type KeyedPathElement,\n  type RelativePosition,\n  type RemoveOp,\n  type ReplaceOp,\n  type TruncateOp,\n  type UpsertOp,\n} from '../../../mutations/operations/types'\nimport {findTargetIndex, getTargetIdx, splice} from '../../utils/array'\n\nexport function insert<\n  O extends InsertOp<unknown[], RelativePosition, number | KeyedPathElement>,\n  CurrentValue extends unknown[],\n>(op: O, currentValue: CurrentValue) {\n  if (!Array.isArray(currentValue)) {\n    throw new TypeError('Cannot apply \"insert()\" on non-array value')\n  }\n\n  const index = findTargetIndex(currentValue, op.referenceItem)\n  if (index === null) {\n    throw new Error(`Found no matching array element to insert ${op.position}`)\n  }\n  // special case for empty arrays\n  if (currentValue.length === 0) {\n    return op.items\n  }\n  return splice(currentValue, getTargetIdx(op.position, index), 0, op.items)\n}\n\nexport function upsert<\n  O extends UpsertOp<unknown[], RelativePosition, number | KeyedPathElement>,\n  CurrentValue extends unknown[],\n>(op: O, currentValue: CurrentValue) {\n  if (!Array.isArray(currentValue)) {\n    throw new TypeError('Cannot apply \"upsert()\" on non-array value')\n  }\n\n  if (op.items.length === 0) {\n    return currentValue\n  }\n  const replaceItemsMap: number[] = []\n  const insertItems: unknown[] = []\n  op.items.forEach((itemToBeUpserted: any, i) => {\n    const existingIndex = currentValue.findIndex(\n      existingItem => (existingItem as any)?._key === itemToBeUpserted._key,\n    )\n    if (existingIndex >= 0) {\n      replaceItemsMap[existingIndex] = i\n    } else {\n      insertItems.push(itemToBeUpserted)\n    }\n  })\n\n  if (replaceItemsMap.length === 0 && insertItems.length == 0) {\n    return currentValue\n  }\n\n  const next = [...currentValue]\n  // Replace existing items\n  for (const i of replaceItemsMap) {\n    next[i] = op.items[replaceItemsMap[i]!]!\n  }\n\n  // Insert the items that doesn't exist\n  return insert(\n    {\n      type: 'insert',\n      items: insertItems,\n      referenceItem: op.referenceItem,\n      position: op.position,\n    },\n    next,\n  )\n}\n\nexport function replace<\n  O extends ReplaceOp<unknown[], number | KeyedPathElement>,\n  CurrentValue extends unknown[],\n>(op: O, currentValue: CurrentValue) {\n  if (!Array.isArray(currentValue)) {\n    throw new TypeError('Cannot apply \"replace()\" on non-array value')\n  }\n\n  const index = findTargetIndex(currentValue, op.referenceItem)\n  if (index === null) {\n    throw new Error(`Found no matching array element to replace`)\n  }\n  return splice(currentValue, index, op.items.length, op.items)\n}\nexport function remove<\n  O extends RemoveOp<number | KeyedPathElement>,\n  CurrentValue extends unknown[],\n>(op: O, currentValue: CurrentValue) {\n  if (!Array.isArray(currentValue)) {\n    throw new TypeError('Cannot apply \"remove()\" on non-array value')\n  }\n\n  const index = findTargetIndex(currentValue, op.referenceItem)\n  if (index === null) {\n    throw new Error(`Found no matching array element to replace`)\n  }\n  return splice(currentValue, index, 1, [])\n}\n\nexport function truncate<O extends TruncateOp, CurrentValue extends unknown[]>(\n  op: O,\n  currentValue: CurrentValue,\n) {\n  if (!Array.isArray(currentValue)) {\n    throw new TypeError('Cannot apply \"truncate()\" on non-array value')\n  }\n\n  return typeof op.endIndex === 'number'\n    ? currentValue\n        .slice(0, op.startIndex)\n        .concat(currentValue.slice(op.endIndex))\n    : currentValue.slice(0, op.startIndex)\n}\n","import {\n  type SetIfMissingOp,\n  type SetOp,\n  type UnsetOp,\n} from '../../../mutations/operations/types'\n\nexport function set<O extends SetOp<any>, CurrentValue>(\n  op: O,\n  currentValue: CurrentValue,\n) {\n  return op.value\n}\n\nexport function setIfMissing<O extends SetIfMissingOp<any>, CurrentValue>(\n  op: O,\n  currentValue: CurrentValue,\n) {\n  return currentValue ?? op.value\n}\n\nexport function unset<O extends UnsetOp, CurrentValue>(op: O) {\n  return undefined\n}\n","import {type DecOp, type IncOp} from '../../../mutations/operations/types'\n\nexport function inc<O extends IncOp<number>, CurrentValue extends number>(\n  op: O,\n  currentValue: CurrentValue,\n) {\n  if (typeof currentValue !== 'number') {\n    throw new TypeError('Cannot apply \"inc()\" on non-numeric value')\n  }\n\n  return currentValue + op.amount\n}\n\nexport function dec<O extends DecOp<number>, CurrentValue extends number>(\n  op: O,\n  currentValue: CurrentValue,\n) {\n  if (typeof currentValue !== 'number') {\n    throw new TypeError('Cannot apply \"dec()\" on non-numeric value')\n  }\n\n  return currentValue - op.amount\n}\n","export const hasOwn = Object.prototype.hasOwnProperty.call.bind(\n  Object.prototype.hasOwnProperty,\n)\n","import {hasOwn} from './hasOwn'\n\nexport function isEmpty(v: object) {\n  for (const key in v) {\n    if (hasOwn(v, key)) {\n      return false\n    }\n  }\n  return true\n}\n","export function omit<T, K extends keyof T>(val: T, props: K[]): Omit<T, K> {\n  const copy = {...val}\n  for (const prop of props) {\n    delete copy[prop]\n  }\n  return copy\n}\n","import {\n  type AssignOp,\n  type UnassignOp,\n} from '../../../mutations/operations/types'\nimport {isObject} from '../../../utils/isObject'\nimport {isEmpty} from '../../utils/isEmpty'\nimport {omit} from '../../utils/omit'\n\nexport function unassign<T extends object, K extends string[]>(\n  op: UnassignOp<K>,\n  currentValue: T,\n) {\n  if (!isObject(currentValue)) {\n    throw new TypeError('Cannot apply \"unassign()\" on non-object value')\n  }\n\n  return op.keys.length === 0\n    ? currentValue\n    : omit(currentValue, op.keys as any[])\n}\n\nexport function assign<T extends object>(op: AssignOp<T>, currentValue: T) {\n  if (!isObject(currentValue)) {\n    throw new TypeError('Cannot apply \"assign()\" on non-object value')\n  }\n\n  return isEmpty(op.value) ? currentValue : {...currentValue, ...op.value}\n}\n","import {applyPatches, parsePatch} from '@sanity/diff-match-patch'\n\nimport {type DiffMatchPatchOp} from '../../../mutations/operations/types'\n\nexport function diffMatchPatch<\n  O extends DiffMatchPatchOp,\n  CurrentValue extends string,\n>(op: O, currentValue: CurrentValue) {\n  if (typeof currentValue !== 'string') {\n    throw new TypeError('Cannot apply \"diffMatchPatch()\" on non-string value')\n  }\n\n  return applyPatches(parsePatch(op.value), currentValue)[0]\n}\n","import {\n  type AnyOp,\n  type ArrayOp,\n  type NumberOp,\n  type ObjectOp,\n  type Operation,\n  type StringOp,\n} from '../../mutations/operations/types'\nimport {type AnyArray} from '../../utils/typeUtils'\nimport * as operations from './operations'\nimport {type ApplyOp} from './typings/applyOp'\n\nexport function applyOp<const Op extends AnyOp, const CurrentValue>(\n  op: Op,\n  currentValue: CurrentValue,\n): ApplyOp<Op, CurrentValue>\nexport function applyOp<\n  const Op extends NumberOp,\n  const CurrentValue extends number,\n>(op: Op, currentValue: CurrentValue): ApplyOp<Op, CurrentValue>\nexport function applyOp<\n  const Op extends StringOp,\n  const CurrentValue extends string,\n>(op: Op, currentValue: CurrentValue): ApplyOp<Op, CurrentValue>\nexport function applyOp<\n  const Op extends ObjectOp,\n  const CurrentValue extends {[k in keyof any]: unknown},\n>(op: Op, currentValue: CurrentValue): ApplyOp<Op, CurrentValue>\nexport function applyOp<\n  const Op extends ArrayOp,\n  const CurrentValue extends AnyArray,\n>(op: Op, currentValue: CurrentValue): ApplyOp<Op, CurrentValue>\nexport function applyOp<const Op extends Operation, const CurrentValue>(\n  op: Op,\n  currentValue: CurrentValue,\n): ApplyOp<Op, CurrentValue> {\n  if (!(op.type in operations)) {\n    throw new Error(`Invalid operation type: \"${op.type}\"`)\n  }\n\n  return (operations[op.type] as CallableFunction)(op, currentValue)\n}\n","import {type Operation} from '../../mutations/operations/types'\nimport {type NodePatch, type NodePatchList} from '../../mutations/types'\nimport {isArrayElement, isPropertyElement, stringify} from '../../path'\nimport {isObject} from '../../utils/isObject'\nimport {type NormalizeReadOnlyArray} from '../../utils/typeUtils'\nimport {type KeyedPathElement, type Path} from '../'\nimport {findTargetIndex, splice} from '../utils/array'\nimport {applyOp} from './applyOp'\nimport {\n  type ApplyAtPath,\n  type ApplyNodePatch,\n  type ApplyPatches,\n} from './typings/applyNodePatch'\n\nexport function applyPatches<Patches extends NodePatchList, const Doc>(\n  patches: Patches,\n  document: Doc,\n): ApplyPatches<NormalizeReadOnlyArray<Patches>, Doc> {\n  return (patches as NodePatch[]).reduce(\n    (prev, patch) => applyNodePatch(patch, prev) as any,\n    document,\n  ) as any\n}\n\nexport function applyNodePatch<const Patch extends NodePatch, const Doc>(\n  patch: Patch,\n  document: Doc,\n): ApplyNodePatch<Patch, Doc> {\n  return applyAtPath(patch.path, patch.op, document) as any\n}\n\nfunction applyAtPath<P extends Path, O extends Operation, T>(\n  path: P,\n  op: O,\n  value: T,\n): ApplyAtPath<P, O, T> {\n  if (!isNonEmptyArray(path)) {\n    return applyOp(op as any, value) as any\n  }\n\n  const [head, ...tail] = path\n\n  if (isArrayElement(head) && Array.isArray(value)) {\n    return applyInArray(head, tail, op, value) as any\n  }\n\n  if (isPropertyElement(head) && isObject(value)) {\n    return applyInObject(head, tail, op, value) as any\n  }\n\n  throw new Error(\n    `Cannot apply operation of type \"${op.type}\" to path ${stringify(\n      path,\n    )} on ${typeof value} value`,\n  )\n}\n\nfunction applyInObject<Key extends keyof any, T extends {[key in Key]?: any}>(\n  head: Key,\n  tail: Path,\n  op: Operation,\n  object: T,\n) {\n  const current = object[head]\n\n  if (current === undefined && tail.length > 0) {\n    return object\n  }\n\n  // The patch targets the item at the index specified by \"head\"\n  // so forward it to the item\n  const patchedValue = applyAtPath(tail, op, current)\n\n  // If the result of applying it to the item yields the item back we assume it was\n  // a noop and don't modify our value. If we get a new value back, we return a\n  // new array with the modified item replaced\n  return patchedValue === current ? object : {...object, [head]: patchedValue}\n}\n\nfunction applyInArray<T>(\n  head: number | KeyedPathElement,\n  tail: Path,\n  op: Operation,\n  value: T[],\n) {\n  const index = findTargetIndex(value, head!)\n\n  if (index === null) {\n    // partial is default behavior for arrays\n    // the patch targets an index that is out of bounds\n    return value\n  }\n\n  // If the given selector could not be found, return as-is\n  if (index === -1) {\n    return value\n  }\n\n  const current = value[index]!\n\n  // The patch targets the item at the index specified by \"head\"\n  // so forward it to the item\n  const patchedItem = applyAtPath(tail, op, current)\n\n  // If the result of applying it to the item yields the item back we assume it was\n  // a noop and don't modify our value. If we get a new value back, we return a\n  // new array with the modified item replaced\n  return patchedItem === current\n    ? value\n    : splice(value, index, 1, [patchedItem])\n}\n\nfunction isNonEmptyArray<T>(a: T[] | readonly T[]): a is [T, ...T[]] {\n  return a.length > 0\n}\n","import {type PatchMutation, type SanityDocumentBase} from '../mutations/types'\nimport {type NormalizeReadOnlyArray} from '../utils/typeUtils'\nimport {applyPatches} from './patch/applyNodePatch'\nimport {type ApplyPatches} from './patch/typings/applyNodePatch'\n\nexport type ApplyPatchMutation<\n  Mutation extends PatchMutation,\n  Doc extends SanityDocumentBase,\n> =\n  Mutation extends PatchMutation<infer Patches>\n    ? ApplyPatches<NormalizeReadOnlyArray<Patches>, Doc>\n    : Doc\n\nexport function applyPatchMutation<\n  const Mutation extends PatchMutation,\n  const Doc extends SanityDocumentBase,\n>(mutation: Mutation, document: Doc): ApplyPatchMutation<Mutation, Doc> {\n  if (\n    mutation.options?.ifRevision &&\n    document._rev !== mutation.options.ifRevision\n  ) {\n    throw new Error('Revision mismatch')\n  }\n  if (mutation.id !== document._id) {\n    throw new Error(\n      `Document id mismatch. Refusing to apply mutation for document with id=\"${mutation.id}\" on the given document with id=\"${document._id}\"`,\n    )\n  }\n  return applyPatches(mutation.patches, document) as any\n}\n","import {type SanityDocumentBase} from '../../mutations/types'\nimport {type StoredDocument} from '../applyInIndex'\n\nexport function hasId(doc: SanityDocumentBase): doc is StoredDocument {\n  return '_id' in doc\n}\nexport function assignId<Doc extends SanityDocumentBase>(\n  doc: Doc,\n  generateId: () => string,\n): Doc & {_id: string} {\n  return hasId(doc) ? doc : {...doc, _id: generateId()}\n}\n","import {nanoid} from 'nanoid'\n\nimport {applyPatchMutation, assignId, hasId} from '../../apply'\nimport {\n  type CreateIfNotExistsMutation,\n  type CreateMutation,\n  type CreateOrReplaceMutation,\n  type DeleteMutation,\n  type Mutation,\n  type PatchMutation,\n  type SanityDocumentBase,\n} from '../../mutations/types'\n\nexport type MutationResult<Doc extends SanityDocumentBase> =\n  | {\n      id: string\n      status: 'created'\n      after: Doc\n    }\n  | {\n      id: string\n      status: 'updated'\n      before: Doc\n      after: Doc\n    }\n  | {\n      id: string\n      status: 'deleted'\n      before: Doc | undefined\n      after: undefined\n    }\n  | {\n      status: 'error'\n      message: string\n    }\n  | {\n      status: 'noop'\n    }\n\n/**\n * Applies a set of mutations to the provided document\n * @param current\n * @param mutation\n */\nexport function applyAll<Doc extends SanityDocumentBase>(\n  current: Doc | undefined,\n  mutation: Mutation<Doc>[],\n): Doc | undefined {\n  return mutation.reduce((doc, m) => {\n    const res = applyDocumentMutation(doc, m)\n    if (res.status === 'error') {\n      throw new Error(res.message)\n    }\n    return res.status === 'noop' ? doc : res.after\n  }, current)\n}\n\n/**\n * Applies a mutation to the provided document\n * @param document\n * @param mutation\n */\nexport function applyDocumentMutation<Doc extends SanityDocumentBase>(\n  document: Doc | undefined,\n  mutation: Mutation<Doc>,\n): MutationResult<Doc> {\n  if (mutation.type === 'create') {\n    return create(document, mutation)\n  }\n  if (mutation.type === 'createIfNotExists') {\n    return createIfNotExists(document, mutation)\n  }\n  if (mutation.type === 'delete') {\n    return del(document, mutation)\n  }\n  if (mutation.type === 'createOrReplace') {\n    return createOrReplace(document, mutation)\n  }\n  if (mutation.type === 'patch') {\n    return patch(document, mutation)\n  }\n  // @ts-expect-error all cases should be covered\n  throw new Error(`Invalid mutation type: ${mutation.type}`)\n}\n\nfunction create<Doc extends SanityDocumentBase>(\n  document: Doc | undefined,\n  mutation: CreateMutation<Doc>,\n): MutationResult<Doc> {\n  if (document) {\n    return {status: 'error', message: 'Document already exist'}\n  }\n  const result = assignId(mutation.document, nanoid)\n  return {status: 'created', id: result._id, after: result}\n}\n\nfunction createIfNotExists<Doc extends SanityDocumentBase>(\n  document: Doc | undefined,\n  mutation: CreateIfNotExistsMutation<Doc>,\n): MutationResult<Doc> {\n  if (!hasId(mutation.document)) {\n    return {\n      status: 'error',\n      message: 'Cannot createIfNotExists on document without _id',\n    }\n  }\n  return document\n    ? {status: 'noop'}\n    : {status: 'created', id: mutation.document._id, after: mutation.document}\n}\n\nfunction createOrReplace<Doc extends SanityDocumentBase>(\n  document: Doc | undefined,\n  mutation: CreateOrReplaceMutation<Doc>,\n): MutationResult<Doc> {\n  if (!hasId(mutation.document)) {\n    return {\n      status: 'error',\n      message: 'Cannot createIfNotExists on document without _id',\n    }\n  }\n\n  return document\n    ? {\n        status: 'updated',\n        id: mutation.document._id,\n        before: document,\n        after: mutation.document,\n      }\n    : {status: 'created', id: mutation.document._id, after: mutation.document}\n}\n\nfunction del<Doc extends SanityDocumentBase>(\n  document: Doc | undefined,\n  mutation: DeleteMutation,\n): MutationResult<Doc> {\n  if (!document) {\n    return {status: 'noop'}\n  }\n  if (mutation.id !== document._id) {\n    return {status: 'error', message: 'Delete mutation targeted wrong document'}\n  }\n  return {\n    status: 'deleted',\n    id: mutation.id,\n    before: document,\n    after: undefined,\n  }\n}\n\nfunction patch<Doc extends SanityDocumentBase>(\n  document: Doc | undefined,\n  mutation: PatchMutation,\n): MutationResult<Doc> {\n  if (!document) {\n    return {\n      status: 'error',\n      message: 'Cannot apply patch on nonexistent document',\n    }\n  }\n  const next = applyPatchMutation(mutation, document)\n  return document === next\n    ? {status: 'noop'}\n    : {status: 'updated', id: mutation.id, before: document, after: next}\n}\n","import {type Mutation, type SanityDocumentBase} from '../../mutations/types'\nimport {getMutationDocumentId} from '../utils/getMutationDocumentId'\nimport {applyDocumentMutation} from './applyDocumentMutation'\n\nexport interface UpdateResult<T extends SanityDocumentBase> {\n  id: string\n  status: 'created' | 'updated' | 'deleted'\n  before?: T\n  after?: T\n  mutations: Mutation[]\n}\n\n/**\n * Takes a list of mutations and applies them to documents in a dataset\n */\nexport function applyMutations<T extends SanityDocumentBase>(\n  mutations: Mutation[],\n  dataset: {get: (id: string) => T | undefined},\n): UpdateResult<T>[] {\n  const updatedDocs: Record<\n    string,\n    {\n      before: T | undefined\n      after: T | undefined\n      muts: Mutation[]\n    }\n  > = Object.create(null)\n\n  for (const mutation of mutations) {\n    const documentId = getMutationDocumentId(mutation)\n    if (!documentId) {\n      throw new Error('Unable to get document id from mutation')\n    }\n\n    const before = updatedDocs[documentId]?.after || dataset.get(documentId)\n    const res = applyDocumentMutation(before, mutation)\n    if (res.status === 'error') {\n      throw new Error(res.message)\n    }\n    if (res.status === 'noop') {\n      continue\n    }\n    if (\n      res.status === 'updated' ||\n      res.status === 'created' ||\n      res.status === 'deleted'\n    ) {\n      if (!(documentId in updatedDocs)) {\n        updatedDocs[documentId] = {before, after: undefined, muts: []}\n      }\n      updatedDocs[documentId]!.after = res.after\n    }\n  }\n\n  return Object.entries(updatedDocs).map(\n    // eslint-disable-next-line no-shadow\n    ([id, {before, after, muts}]) => {\n      return {\n        id,\n        status: after ? (before ? 'updated' : 'created') : 'deleted',\n        mutations: muts,\n        before,\n        after,\n      }\n    },\n  )\n}\n","import {type SanityDocumentBase} from '../../mutations/types'\nimport {type Dataset} from '../types'\nimport {type UpdateResult} from './applyMutations'\n\nexport function commit<Doc extends SanityDocumentBase>(\n  results: UpdateResult<Doc>[],\n  dataset: Dataset<Doc>,\n) {\n  results.forEach(result => {\n    if (result.status === 'created' || result.status === 'updated') {\n      dataset.set(result.id, result.after)\n    }\n    if (result.status === 'deleted') {\n      dataset.delete(result.id)\n    }\n  })\n}\n","export function takeUntil<T>(\n  arr: T[],\n  predicate: (item: T) => boolean,\n  opts?: {inclusive: boolean},\n) {\n  const result = []\n  for (const item of arr) {\n    if (predicate(item)) {\n      if (opts?.inclusive) {\n        result.push(item)\n      }\n      return result\n    }\n    result.push(item)\n  }\n  return result\n}\n\nexport function takeUntilRight<T>(\n  arr: T[],\n  predicate: (item: T) => boolean,\n  opts?: {inclusive: boolean},\n) {\n  const result = []\n  for (const item of arr.slice().reverse()) {\n    if (predicate(item)) {\n      if (opts?.inclusive) {\n        result.push(item)\n      }\n      return result\n    }\n    result.push(item)\n  }\n  return result.reverse()\n}\n","import {makePatches, stringifyPatches} from '@sanity/diff-match-patch'\n\nimport {applyNodePatch} from '../../apply'\nimport {type Operation} from '../../mutations/operations/types'\nimport {type NodePatch, type SanityDocumentBase} from '../../mutations/types'\nimport {getAtPath, type Path, startsWith, stringify} from '../../path'\nimport {takeUntilRight} from '../utils/arrayUtils'\n\nfunction isEqualPath(p1: Path, p2: Path) {\n  return stringify(p1) === stringify(p2)\n}\n\nfunction supersedes(later: Operation, earlier: Operation) {\n  return (\n    (earlier.type === 'set' || earlier.type === 'unset') &&\n    (later.type === 'set' || later.type === 'unset')\n  )\n}\n\nexport function squashNodePatches(patches: NodePatch[]) {\n  return compactSetIfMissingPatches(\n    compactSetPatches(compactUnsetPatches(patches)),\n  )\n}\n\nexport function compactUnsetPatches(patches: NodePatch[]) {\n  return patches.reduce(\n    (earlierPatches: NodePatch[], laterPatch: NodePatch) => {\n      if (laterPatch.op.type !== 'unset') {\n        earlierPatches.push(laterPatch)\n        return earlierPatches\n      }\n      // find all preceding patches that are affected by this unset\n      const unaffected = earlierPatches.filter(\n        earlierPatch => !startsWith(laterPatch.path, earlierPatch.path),\n      )\n      unaffected.push(laterPatch)\n      return unaffected\n    },\n    [],\n  )\n}\n\nexport function compactSetPatches(patches: NodePatch[]) {\n  return patches.reduceRight(\n    (laterPatches: NodePatch[], earlierPatch: NodePatch) => {\n      const replacement = laterPatches.find(\n        later =>\n          supersedes(later.op, earlierPatch.op) &&\n          isEqualPath(later.path, earlierPatch.path),\n      )\n      if (replacement) {\n        // we already have another patch later in the chain that replaces this one\n        return laterPatches\n      }\n      laterPatches.unshift(earlierPatch)\n      return laterPatches\n    },\n    [],\n  )\n}\n\nexport function compactSetIfMissingPatches(patches: NodePatch[]) {\n  return patches.reduce(\n    (previousPatches: NodePatch[], laterPatch: NodePatch) => {\n      if (laterPatch.op.type !== 'setIfMissing') {\n        previousPatches.push(laterPatch)\n        return previousPatches\n      }\n      // look at preceding patches up until the first unset\n      const check = takeUntilRight(\n        previousPatches,\n        patch => patch.op.type === 'unset',\n      )\n      const precedent = check.find(\n        precedingPatch =>\n          precedingPatch.op.type === 'setIfMissing' &&\n          isEqualPath(precedingPatch.path, laterPatch.path),\n      )\n      if (precedent) {\n        // we already have an identical patch earlier in the chain that voids this one\n        return previousPatches\n      }\n      previousPatches.push(laterPatch)\n      return previousPatches\n    },\n    [],\n  )\n}\n\nexport function compactDMPSetPatches(\n  base: SanityDocumentBase,\n  patches: NodePatch[],\n) {\n  let edge = base\n  return patches.reduce(\n    (earlierPatches: NodePatch[], laterPatch: NodePatch) => {\n      const before = edge\n      edge = applyNodePatch(laterPatch, edge)\n      if (\n        laterPatch.op.type === 'set' &&\n        typeof laterPatch.op.value === 'string'\n      ) {\n        const current = getAtPath(laterPatch.path, before)\n        if (typeof current === 'string') {\n          // we can replace the earlier diffMatchPatches with a new one\n          const replaced: NodePatch = {\n            ...laterPatch,\n            op: {\n              type: 'diffMatchPatch',\n              value: stringifyPatches(\n                makePatches(current, laterPatch.op.value),\n              ),\n            },\n          }\n          return earlierPatches\n            .flatMap(ep => {\n              return isEqualPath(ep.path, laterPatch.path) &&\n                ep.op.type === 'diffMatchPatch'\n                ? []\n                : ep\n            })\n            .concat(replaced)\n        }\n      }\n      earlierPatches.push(laterPatch)\n      return earlierPatches\n    },\n    [],\n  )\n}\n","import {\n  type Mutation,\n  type NodePatch,\n  type PatchMutation,\n  type SanityDocumentBase,\n} from '../../mutations/types'\nimport {type MutationGroup} from '../types'\nimport {compactDMPSetPatches} from './squashNodePatches'\n\nexport interface DataStore {\n  get: (id: string) => SanityDocumentBase | undefined\n}\nexport function squashDMPStrings(\n  remote: DataStore,\n  mutationGroups: MutationGroup[],\n): MutationGroup[] {\n  return mutationGroups.map(mutationGroup => ({\n    ...mutationGroup,\n    mutations: dmpIfyMutations(remote, mutationGroup.mutations),\n  }))\n}\n\nexport function dmpIfyMutations(\n  store: DataStore,\n  mutations: Mutation[],\n): Mutation[] {\n  return mutations.map((mutation, i) => {\n    return mutation.type === 'patch'\n      ? dmpifyPatchMutation(store.get(mutation.id), mutation)\n      : mutation\n  })\n}\n\nexport function dmpifyPatchMutation(\n  base: SanityDocumentBase | undefined,\n  mutation: PatchMutation,\n): PatchMutation {\n  if (!base) {\n    return mutation\n  }\n  return {\n    ...mutation,\n    patches: compactDMPSetPatches(base, mutation.patches as NodePatch[]),\n  }\n}\n","import {type MutationGroup} from '../types'\n\n/**\n * Merges adjacent non-transactional mutation groups, interleaving transactional mutations as-is\n * @param mutationGroups\n */\nexport function mergeMutationGroups(\n  mutationGroups: MutationGroup[],\n): MutationGroup[] {\n  return chunkWhile(mutationGroups, group => !group.transaction).flatMap(\n    chunk => ({\n      ...chunk[0]!,\n      mutations: chunk.flatMap(c => c.mutations),\n    }),\n  )\n}\n\n/**\n * Groups subsequent mutations into transactions, leaves transactions as-is\n * @param arr\n * @param predicate\n */\nexport function chunkWhile<T>(\n  arr: T[],\n  predicate: (item: T) => boolean,\n): T[][] {\n  const res: T[][] = []\n  let currentChunk: T[] = []\n  arr.forEach(item => {\n    if (predicate(item)) {\n      currentChunk.push(item)\n    } else {\n      if (currentChunk.length > 0) {\n        res.push(currentChunk)\n      }\n      currentChunk = []\n      res.push([item])\n    }\n  })\n  if (currentChunk.length > 0) {\n    res.push(currentChunk)\n  }\n  return res\n}\n","import {groupBy} from 'lodash'\n\nimport {type Mutation, type NodePatch} from '../../mutations/types'\nimport {type MutationGroup} from '../types'\nimport {takeUntilRight} from '../utils/arrayUtils'\nimport {getMutationDocumentId} from '../utils/getMutationDocumentId'\nimport {mergeMutationGroups} from '../utils/mergeMutationGroups'\nimport {squashNodePatches} from './squashNodePatches'\n\nexport function squashMutationGroups(staged: MutationGroup[]): MutationGroup[] {\n  return mergeMutationGroups(staged)\n    .map(transaction => ({\n      ...transaction,\n      mutations: squashMutations(transaction.mutations),\n    }))\n    .map(transaction => ({\n      ...transaction,\n      mutations: transaction.mutations.map(mutation => {\n        if (mutation.type !== 'patch') {\n          return mutation\n        }\n        return {\n          ...mutation,\n          patches: squashNodePatches(mutation.patches as NodePatch[]),\n        }\n      }),\n    }))\n}\n\ntype FIXME = Mutation[]\n\n/*\n assumptions:\n the order documents appear with their mutations within the same transaction doesn't matter\n */\nexport function squashMutations(mutations: Mutation[]): Mutation[] {\n  const byDocument = groupBy(mutations, getMutationDocumentId)\n  return Object.values(byDocument).flatMap(documentMutations => {\n    // these are the mutations that happens for the document with <id> within the same transactions\n    return squashCreateIfNotExists(squashDelete(documentMutations as FIXME))\n      .flat()\n      .reduce((acc: Mutation[], docMutation) => {\n        const prev = acc[acc.length - 1]\n        if ((!prev || prev.type === 'patch') && docMutation.type === 'patch') {\n          return acc.slice(0, -1).concat({\n            ...docMutation,\n            patches: (prev?.patches || []).concat(docMutation.patches),\n          })\n        }\n        return acc.concat(docMutation)\n      }, [])\n  })\n}\n\n/**\n * WARNING: This assumes that the mutations are only for a single document\n * @param mutations\n */\nexport function squashCreateIfNotExists(mutations: Mutation[]): Mutation[] {\n  if (mutations.length === 0) {\n    return mutations\n  }\n\n  return mutations.reduce((previousMuts: Mutation[], laterMut: Mutation) => {\n    if (laterMut.type !== 'createIfNotExists') {\n      previousMuts.push(laterMut)\n      return previousMuts\n    }\n    const prev = takeUntilRight(previousMuts, m => m.type === 'delete')\n    const precedent = prev.find(\n      precedingPatch => precedingPatch.type === 'createIfNotExists',\n    )\n    if (precedent) {\n      // we already have an identical patch earlier in the chain that voids this one\n      return previousMuts\n    }\n    previousMuts.push(laterMut)\n    return previousMuts\n  }, [])\n}\n\nfunction squashDelete(mutations: Mutation[]): Mutation[] {\n  if (mutations.length === 0) {\n    return mutations\n  }\n\n  return mutations.reduce((previousMuts: Mutation[], laterMut: Mutation) => {\n    if (laterMut.type === 'delete') {\n      return [laterMut]\n    }\n    previousMuts.push(laterMut)\n    return previousMuts\n  }, [])\n}\n","import {applyPatches} from '../apply'\nimport {\n  type Mutation,\n  type NodePatch,\n  type PatchMutation,\n  type SanityDocumentBase,\n} from '../mutations/types'\nimport {getAtPath} from '../path'\nimport {applyAll} from './datasets/applyDocumentMutation'\nimport {compactDMPSetPatches} from './optimizations/squashNodePatches'\nimport {type MutationGroup} from './types'\nimport {getMutationDocumentId} from './utils/getMutationDocumentId'\n\ntype RebaseTransaction = {\n  mutations: Mutation[]\n}\n\ntype FlatMutation = Exclude<Mutation, PatchMutation>\n\nfunction flattenMutations(mutations: Mutation[]) {\n  return mutations.flatMap((mut): Mutation | Mutation[] => {\n    if (mut.type === 'patch') {\n      return mut.patches.map(\n        (patch): PatchMutation => ({\n          type: 'patch',\n          id: mut.id,\n          patches: [patch],\n        }),\n      )\n    }\n    return mut\n  })\n}\n\nexport function rebase(\n  documentId: string,\n  oldBase: SanityDocumentBase | undefined,\n  newBase: SanityDocumentBase | undefined,\n  stagedMutations: MutationGroup[],\n): [newStage: MutationGroup[], rebased: SanityDocumentBase | undefined] {\n  // const flattened = flattenMutations(newStage.flatMap(t => t.mutations))\n\n  // 1. get the dmpified mutations from the newStage based on the old base\n  // 2. apply those to the new base\n  // 3. convert those back into set patches based on the new base and return as a new newStage\n  let edge = oldBase\n  const dmpified = stagedMutations.map(transaction => {\n    const mutations = transaction.mutations.flatMap(mut => {\n      if (getMutationDocumentId(mut) !== documentId) {\n        return []\n      }\n      const before = edge\n      edge = applyAll(edge, [mut])\n      if (!before) {\n        return mut\n      }\n      if (mut.type !== 'patch') {\n        return mut\n      }\n      return {\n        type: 'dmpified' as const,\n        mutation: {\n          ...mut,\n          // Todo: make compactDMPSetPatches return pairs of patches that was dmpified with their\n          //  original as dmpPatches and original is not 1:1 (e..g some of the original may not be dmpified)\n          dmpPatches: compactDMPSetPatches(before, mut.patches as NodePatch[]),\n          original: mut.patches,\n        },\n      }\n    })\n    return {...transaction, mutations}\n  })\n\n  let newBaseWithDMPForOldBaseApplied: SanityDocumentBase | undefined = newBase\n  // NOTE: It might not be possible to apply them - if so, we fall back to applying the pending changes\n  // todo: revisit this\n  const appliedCleanly = dmpified.map(transaction => {\n    const applied = []\n    return transaction.mutations.forEach(mut => {\n      if (mut.type === 'dmpified') {\n        // go through all dmpified, try to apply, if they fail, use the original un-optimized set patch instead\n        try {\n          newBaseWithDMPForOldBaseApplied = applyPatches(\n            mut.mutation.dmpPatches,\n            newBaseWithDMPForOldBaseApplied,\n          )\n          applied.push(mut)\n        } catch (err) {\n          // eslint-disable-next-line no-console\n          console.warn('Failed to apply dmp patch, falling back to original')\n          try {\n            newBaseWithDMPForOldBaseApplied = applyPatches(\n              mut.mutation.original,\n              newBaseWithDMPForOldBaseApplied,\n            )\n            applied.push(mut)\n          } catch (second: any) {\n            throw new Error(\n              `Failed to apply patch for document \"${documentId}\": ${second.message}`,\n            )\n          }\n        }\n      } else {\n        newBaseWithDMPForOldBaseApplied = applyAll(\n          newBaseWithDMPForOldBaseApplied,\n          [mut],\n        )\n      }\n    })\n  })\n\n  const newStage = stagedMutations.map((transaction): MutationGroup => {\n    // update all set patches to set to the current value\n    return {\n      ...transaction,\n      mutations: transaction.mutations.map(mut => {\n        if (mut.type !== 'patch' || getMutationDocumentId(mut) !== documentId) {\n          return mut\n        }\n        return {\n          ...mut,\n          patches: mut.patches.map(patch => {\n            if (patch.op.type !== 'set') {\n              return patch\n            }\n            return {\n              ...patch,\n              op: {\n                ...patch.op,\n                value: getAtPath(patch.path, newBaseWithDMPForOldBaseApplied),\n              },\n            }\n          }),\n        }\n      }),\n    }\n  })\n  return [newStage, newBaseWithDMPForOldBaseApplied]\n}\n","import type {Transaction} from '../_unstable_store'\nimport type {MutationGroup} from './types'\n\nexport function toTransactions(groups: MutationGroup[]): Transaction[] {\n  return groups.map(group => {\n    if (group.transaction && group.id !== undefined) {\n      return {id: group.id!, mutations: group.mutations}\n    }\n    return {mutations: group.mutations}\n  })\n}\n","import {\n  type Mutation,\n  type NodePatch,\n  type Transaction,\n} from '../../mutations/types'\nimport {stringify as stringifyPath} from '../../path/parser/stringify'\n\nexport function encode(mutation: Mutation) {\n  return encodeMutation(mutation)\n}\n\nexport function encodeAll(mutations: Mutation[]) {\n  return mutations.flatMap(encode)\n}\n\nexport function encodeTransaction(transaction: Transaction) {\n  return {\n    transactionId: transaction.id,\n    mutations: encodeAll(transaction.mutations),\n  }\n}\n\nexport function encodeMutation(mutation: Mutation) {\n  if (\n    mutation.type === 'create' ||\n    mutation.type === 'createIfNotExists' ||\n    mutation.type === 'createOrReplace'\n  ) {\n    return {[mutation.type]: mutation.document}\n  }\n  if (mutation.type === 'delete') {\n    return {\n      delete: {id: mutation.id},\n    }\n  }\n  const ifRevisionID = mutation.options?.ifRevision\n  return mutation.patches.map(patch => {\n    return {\n      patch: {\n        id: mutation.id,\n        ...(ifRevisionID && {ifRevisionID}),\n        ...patchToSanity(patch),\n      },\n    }\n  })\n}\n\nfunction patchToSanity(patch: NodePatch) {\n  const {path, op} = patch\n  if (op.type === 'unset') {\n    return {unset: [stringifyPath(path)]}\n  }\n  if (op.type === 'insert') {\n    return {\n      insert: {\n        [op.position]: stringifyPath([...path, op.referenceItem]),\n        items: op.items,\n      },\n    }\n  }\n  if (op.type === 'diffMatchPatch') {\n    return {diffMatchPatch: {[stringifyPath(path)]: op.value}}\n  }\n  if (op.type === 'inc') {\n    return {inc: {[stringifyPath(path)]: op.amount}}\n  }\n  if (op.type === 'dec') {\n    return {dec: {[stringifyPath(path)]: op.amount}}\n  }\n  if (op.type === 'set' || op.type === 'setIfMissing') {\n    return {[op.type]: {[stringifyPath(path)]: op.value}}\n  }\n  if (op.type === 'truncate') {\n    const range = [\n      op.startIndex,\n      typeof op.endIndex === 'number' ? op.endIndex : '',\n    ].join(':')\n\n    return {unset: [`${stringifyPath(path)}[${range}]`]}\n  }\n  if (op.type === 'upsert') {\n    // note: upsert currently not supported by sanity, so will always insert at reference position\n    return {\n      unset: op.items.map(item =>\n        stringifyPath([...path, {_key: (item as any)._key}]),\n      ),\n      insert: {\n        [op.position]: stringifyPath([...path, op.referenceItem]),\n        items: op.items,\n      },\n    }\n  }\n  if (op.type === 'assign') {\n    return {\n      set: Object.fromEntries(\n        Object.keys(op.value).map(key => [\n          stringifyPath(path.concat(key)),\n          op.value[key as keyof typeof op.value],\n        ]),\n      ),\n    }\n  }\n  if (op.type === 'unassign') {\n    return {\n      unset: op.keys.map(key => stringifyPath(path.concat(key))),\n    }\n  }\n  if (op.type === 'replace') {\n    return {\n      insert: {\n        replace: stringifyPath(path.concat(op.referenceItem)),\n        items: op.items,\n      },\n    }\n  }\n  if (op.type === 'remove') {\n    return {\n      unset: [stringifyPath(path.concat(op.referenceItem))],\n    }\n  }\n  //@ts-expect-error all cases should be covered\n  throw new Error(`Unknown operation type ${op.type}`)\n}\n","import {\n  type MutationEvent,\n  type ReconnectEvent,\n  type SanityClient,\n  type WelcomeEvent,\n} from '@sanity/client'\nimport {filter, merge, type ObservedValueOf, share, shareReplay} from 'rxjs'\n\n/**\n * Creates a single, shared, listener EventSource that strems remote mutations, and notifies when it's online (welcome), offline (reconnect).\n */\nexport function createSharedListener(client: SanityClient) {\n  const allEvents$ = client\n    .listen(\n      '*[!(_id in path(\"_.**\"))]',\n      {},\n      {\n        events: ['welcome', 'mutation', 'reconnect'],\n        includeResult: false,\n        includePreviousRevision: false,\n        visibility: 'transaction',\n        effectFormat: 'mendoza',\n        includeMutations: false,\n      },\n    )\n    .pipe(share({resetOnRefCountZero: true}))\n\n  // Reconnect events emitted in case the connection is lost\n  const reconnect = allEvents$.pipe(\n    filter((event): event is ReconnectEvent => event.type === 'reconnect'),\n  )\n\n  // Welcome events are emitted when the listener is (re)connected\n  const welcome = allEvents$.pipe(\n    filter((event): event is WelcomeEvent => event.type === 'welcome'),\n  )\n\n  // Mutation events coming from the listener\n  const mutations = allEvents$.pipe(\n    filter((event): event is MutationEvent => event.type === 'mutation'),\n  )\n\n  // Replay the latest connection event that was emitted either when the connection was disconnected ('reconnect'), established or re-established ('welcome')\n  const connectionEvent = merge(welcome, reconnect).pipe(\n    shareReplay({bufferSize: 1, refCount: true}),\n  )\n\n  // Emit the welcome event if the latest connection event was the 'welcome' event.\n  // Downstream subscribers will typically map the welcome event to an initial fetch\n  const replayWelcome = connectionEvent.pipe(\n    filter(latestConnectionEvent => latestConnectionEvent.type === 'welcome'),\n  )\n\n  // Combine into a single stream\n  return merge(replayWelcome, mutations, reconnect)\n}\n\nexport type SharedListenerEvents = ObservedValueOf<\n  ReturnType<typeof createSharedListener>\n>\n","import {\n  type MutationEvent,\n  type SanityClient,\n  type SanityDocument,\n} from '@sanity/client'\nimport {applyPatch, type RawPatch} from 'mendoza'\nimport {asapScheduler, defer, filter, observeOn} from 'rxjs'\nimport {\n  assertEvent,\n  assign,\n  enqueueActions,\n  fromEventObservable,\n  fromPromise,\n  raise,\n  sendParent,\n  setup,\n  spawnChild,\n  stopChild,\n} from 'xstate'\n\nimport {encodeTransaction, type Mutation} from '../encoders/sanity'\nimport {\n  type MutationGroup,\n  type SanityDocumentBase,\n  type Transaction,\n} from '../store'\nimport {applyMutations} from '../store/datasets/applyMutations'\nimport {commit} from '../store/datasets/commit'\nimport {squashDMPStrings} from '../store/optimizations/squashDMPStrings'\nimport {squashMutationGroups} from '../store/optimizations/squashMutations'\nimport {rebase} from '../store/rebase'\nimport {toTransactions} from '../store/toTransactions'\nimport {createSharedListener, type SharedListenerEvents} from './listener'\n\nexport interface DocumentMutatorMachineInput {\n  id: string\n  client: SanityClient\n  /** A shared listener can be provided, if not it'll be created using `client.listen()` */\n  sharedListener?: ReturnType<typeof createSharedListener>\n  /* Preferrably a LRU cache map that is compatible with an ES6 Map, and have documents that allow unique ids to a particular dataset */\n  cache?: Map<string, SanityDocument<DocumentType> | null>\n}\n\nexport type DocumentMutatorMachineParentEvent =\n  | {type: 'sync'; id: string; document: SanityDocumentBase}\n  | {\n      type: 'mutation'\n      id: string\n      effects: {apply: RawPatch}\n      previousRev: string\n      resultRev: string\n    }\n  | {type: 'rebased.local'; id: string; document: SanityDocumentBase}\n  | {type: 'rebased.remote'; id: string; document: SanityDocumentBase}\n  | {type: 'pristine'; id: string}\n\nexport const documentMutatorMachine = setup({\n  types: {} as {\n    children: {\n      getDocument: 'fetch remote snapshot'\n      submitTransactions: 'submit mutations as transactions'\n    }\n    tags: 'busy' | 'error' | 'ready'\n    context: {\n      client: SanityClient\n      /** A shared listener can be provided, if not it'll be created using `client.listen()` */\n      sharedListener?: ReturnType<typeof createSharedListener>\n      /** The document id */\n      id: string\n      /* Preferrably a LRU cache map that is compatible with an ES6 Map, and have documents that allow unique ids to a particular dataset */\n      cache?: Map<string, SanityDocument<DocumentType> | null>\n      /* The remote snapshot of what the document looks like in Content Lake, kept in sync by applying Mendoza patches in real time. undefined means it's unknown if it exists yet, null means its known that it doesn't exist. */\n      remote: SanityDocument<DocumentType> | null | undefined\n      /* Local snapshot, that is rebased to the remote snapshot whenever that snapshot changes, and allows optimistic local mutations. undefined means it's unknown if the document exists in content lake yet, if both `remote` and `local` is `null` it means it's known that it doesn't exist. If `remote` is defined, and `local` is `null` it means it's optimistically deleted. If `remote` is `null` and `local` defined then it's optimistically created. */\n      local: SanityDocument<DocumentType> | null | undefined\n      /* Remote mendoza mutation events, needs a better name to differentiate from optimistic mutations */\n      mutationEvents: MutationEvent[]\n      /* Track staged mutations that can be submitted */\n      stagedChanges: MutationGroup[]\n      /* Queue mutations mutations that should be staged after an ongoing submission settles */\n      stashedChanges: MutationGroup[]\n      /* Any kind of error object that the UI can parse and decide how to display/report */\n      error: unknown\n      /* Used for automatic retrying of loading the remote snapshot */\n      fetchRemoteSnapshotAttempts: number\n      /* Used for automatic retrying of submitting mutations to Content Lake as a transaction */\n      submitTransactionsAttempts: number\n    }\n    events:\n      | SharedListenerEvents\n      | {type: 'error'}\n      | {type: 'retry'}\n      | {type: 'connect'}\n      | {type: 'reconnect'}\n      | {type: 'welcome'}\n      | {type: 'mutate'; mutations: Mutation[]}\n      | {type: 'submit'}\n      | {\n          type: 'xstate.done.actor.getDocument'\n          output: SanityDocument<DocumentType>\n        }\n      | {\n          type: 'xstate.done.actor.submitTransactions'\n          output: undefined\n        }\n    input: DocumentMutatorMachineInput\n  },\n  actions: {\n    'assign error to context': assign({error: ({event}) => event}),\n    'clear error from context': assign({error: undefined}),\n    'connect to server-sent events': raise({type: 'connect'}),\n    'listen to server-sent events': spawnChild('server-sent events', {\n      id: 'listener',\n      input: ({context}) => ({\n        listener:\n          context.sharedListener || createSharedListener(context.client),\n        id: context.id,\n      }),\n    }),\n    'stop listening to server-sent events': stopChild('listener'),\n    'buffer remote mutation events': assign({\n      mutationEvents: ({event, context}) => {\n        assertEvent(event, 'mutation')\n        return [...context.mutationEvents, event]\n      },\n    }),\n    'restore stashed changes': assign({\n      stagedChanges: ({event, context}) => {\n        assertEvent(event, 'xstate.done.actor.submitTransactions')\n        return context.stashedChanges\n      },\n      stashedChanges: [],\n    }),\n    'rebase fetched remote snapshot': enqueueActions(({enqueue}) => {\n      enqueue.assign(({event, context}) => {\n        assertEvent(event, 'xstate.done.actor.getDocument')\n        const previousRemote = context.remote\n        let nextRemote = event.output\n\n        /**\n         * We assume all patches that happen while we're waiting for the document to resolve are already applied.\n         * But if we do see a patch that has the same revision as the document we just fetched, we should apply any patches following it\n         */\n        let seenCurrentRev = false\n        for (const patch of context.mutationEvents) {\n          if (\n            !patch.effects?.apply ||\n            (!patch.previousRev && patch.transition !== 'appear')\n          )\n            continue\n          if (!seenCurrentRev && patch.previousRev === nextRemote?._rev) {\n            seenCurrentRev = true\n          }\n          if (seenCurrentRev) {\n            nextRemote = applyMendozaPatch(\n              nextRemote,\n              patch.effects.apply,\n              patch.resultRev,\n            )\n          }\n        }\n\n        if (\n          context.cache &&\n          // If the shared cache don't have the document already we can just set it\n          (!context.cache.has(context.id) ||\n            // But when it's in the cache, make sure it's necessary to update it\n            context.cache.get(context.id)!._rev !== nextRemote?._rev)\n        ) {\n          context.cache.set(context.id, nextRemote as unknown as any)\n        }\n\n        const [stagedChanges, local] = rebase(\n          context.id,\n          // It's annoying to convert between null and undefined, reach consensus\n          previousRemote === null ? undefined : previousRemote,\n          nextRemote === null ? undefined : (nextRemote as unknown as any),\n          context.stagedChanges,\n        )\n\n        return {\n          remote: nextRemote as unknown as any,\n          local: local as unknown as any,\n          stagedChanges,\n          // Since the snapshot handler applies all the patches they are no longer needed, allow GC\n          mutationEvents: [],\n        }\n      })\n      enqueue.sendParent(\n        ({context}) =>\n          ({\n            type: 'rebased.remote',\n            id: context.id,\n            document: context.remote!,\n          }) satisfies DocumentMutatorMachineParentEvent,\n      )\n    }),\n    'apply mendoza patch': assign(({event, context}) => {\n      assertEvent(event, 'mutation')\n      const previousRemote = context.remote\n      // We have already seen this mutation\n      if (event.transactionId === previousRemote?._rev) {\n        return {}\n      }\n\n      const nextRemote = applyMendozaPatch(\n        previousRemote!,\n        event.effects!.apply,\n        event.resultRev,\n      )\n\n      if (\n        context.cache &&\n        // If the shared cache don't have the document already we can just set it\n        (!context.cache.has(context.id) ||\n          // But when it's in the cache, make sure it's necessary to update it\n          context.cache.get(context.id)!._rev !== nextRemote?._rev)\n      ) {\n        context.cache.set(context.id, nextRemote as unknown as any)\n      }\n\n      const [stagedChanges, local] = rebase(\n        context.id,\n        // It's annoying to convert between null and undefined, reach consensus\n        previousRemote === null ? undefined : previousRemote,\n        nextRemote === null ? undefined : (nextRemote as unknown as any),\n        context.stagedChanges,\n      )\n\n      return {\n        remote: nextRemote as unknown as any,\n        local: local as unknown as any,\n        stagedChanges,\n      }\n    }),\n    'increment fetch attempts': assign({\n      fetchRemoteSnapshotAttempts: ({context}) =>\n        context.fetchRemoteSnapshotAttempts + 1,\n    }),\n    'reset fetch attempts': assign({\n      fetchRemoteSnapshotAttempts: 0,\n    }),\n    'increment submit attempts': assign({\n      submitTransactionsAttempts: ({context}) =>\n        context.submitTransactionsAttempts + 1,\n    }),\n    'reset submit attempts': assign({\n      submitTransactionsAttempts: 0,\n    }),\n    'stage mutation': assign({\n      stagedChanges: ({event, context}) => {\n        assertEvent(event, 'mutate')\n        return [\n          ...context.stagedChanges,\n          {transaction: false, mutations: event.mutations},\n        ]\n      },\n    }),\n    'stash mutation': assign({\n      stashedChanges: ({event, context}) => {\n        assertEvent(event, 'mutate')\n        return [\n          ...context.stashedChanges,\n          {transaction: false, mutations: event.mutations},\n        ]\n      },\n    }),\n    'rebase local snapshot': enqueueActions(({enqueue}) => {\n      enqueue.assign({\n        local: ({event, context}) => {\n          assertEvent(event, 'mutate')\n          // @TODO would be helpful to not have to convert back and forth between maps\n          const localDataset = new Map()\n          if (context.local) {\n            localDataset.set(context.id, context.local)\n          }\n          // Apply mutations to local dataset (note: this is immutable, and doesn't change the dataset)\n          const results = applyMutations(event.mutations, localDataset)\n          // Write the updated results back to the \"local\" dataset\n          commit(results, localDataset)\n          // Read the result from the local dataset again\n          return localDataset.get(context.id)\n        },\n      })\n      enqueue.sendParent(\n        ({context}) =>\n          ({\n            type: 'rebased.local',\n            id: context.id,\n            document: context.local!,\n          }) satisfies DocumentMutatorMachineParentEvent,\n      )\n    }),\n    'send pristine event to parent': sendParent(\n      ({context}) =>\n        ({\n          type: 'pristine',\n          id: context.id,\n        }) satisfies DocumentMutatorMachineParentEvent,\n    ),\n    'send sync event to parent': sendParent(\n      ({context}) =>\n        ({\n          type: 'sync',\n          id: context.id,\n          document: context.remote!,\n        }) satisfies DocumentMutatorMachineParentEvent,\n    ),\n    'send mutation event to parent': sendParent(({context, event}) => {\n      assertEvent(event, 'mutation')\n      return {\n        type: 'mutation',\n        id: context.id,\n        previousRev: event.previousRev!,\n        resultRev: event.resultRev!,\n        effects: event.effects!,\n      } satisfies DocumentMutatorMachineParentEvent\n    }),\n  },\n  actors: {\n    'server-sent events': fromEventObservable(\n      ({\n        input,\n      }: {\n        input: {listener: ReturnType<typeof createSharedListener>; id: string}\n      }) => {\n        const {listener, id} = input\n        return defer(() => listener).pipe(\n          filter(\n            event =>\n              event.type === 'welcome' ||\n              event.type === 'reconnect' ||\n              (event.type === 'mutation' && event.documentId === id),\n          ),\n          // This is necessary to avoid sync emitted events from `shareReplay` from happening before the actor is ready to receive them\n          observeOn(asapScheduler),\n        )\n      },\n    ),\n    'fetch remote snapshot': fromPromise(\n      async ({\n        input,\n        signal,\n      }: {\n        input: {client: SanityClient; id: string}\n        signal: AbortSignal\n      }) => {\n        const {client, id} = input\n        const document = await client\n          .getDocument(id, {\n            signal,\n          })\n          .catch(e => {\n            if (e instanceof Error && e.name === 'AbortError') return\n            throw e\n          })\n\n        return document\n      },\n    ),\n    'submit mutations as transactions': fromPromise(\n      async ({\n        input,\n        signal,\n      }: {\n        input: {client: SanityClient; transactions: Transaction[]}\n        signal: AbortSignal\n      }) => {\n        const {client, transactions} = input\n        for (const transaction of transactions) {\n          if (signal.aborted) return\n          await client\n            .dataRequest('mutate', encodeTransaction(transaction), {\n              visibility: 'async',\n              returnDocuments: false,\n              signal,\n            })\n            .catch(e => {\n              if (e instanceof Error && e.name === 'AbortError') return\n              throw e\n            })\n        }\n      },\n    ),\n  },\n  delays: {\n    // Exponential backoff delay function\n    fetchRemoteSnapshotTimeout: ({context}) =>\n      Math.pow(2, context.fetchRemoteSnapshotAttempts) * 1000,\n    submitTransactionsTimeout: ({context}) =>\n      Math.pow(2, context.submitTransactionsAttempts) * 1000,\n  },\n}).createMachine({\n  /** @xstate-layout N4IgpgJg5mDOIC5QQPYGMCuBbMA7ALgLRYb4CG+KATgMQnn5gDaADALqKgAOKsAlvj4pcnEAA9EADhYAWAHQA2GSwUBmAKwBOaQEZJkhQBoQAT0Q6ATAF8rx1JhwFipCtTkQ+sNMNxg0jCBpvXF9-Vg4kEB5+QWFRCQQLFhY5PQB2dRU1SQsdGSVjMwRlHTkWNM00nR1VKryKmzt0bDwielcqOWDQwVwoGgB3MAAbbxxw0WiBIRFIhPUKuQ1NVU0tTU0WFdVCxAt1dTlNhX2WdRltGUk061sQexandspO7r9e-qo-H3eJyKnYrNQPNJJollpVutNttdghVCo5MoTgoMpo8jIkqpGvdmo42i4Xl0fv4+H0aGAqFRqH9uLxpnE5ogFrCLFd5CtNBYFJkdOpuaosXcHnjnAw3G9-AAxMh8YYYL5BYn4GlROmA+KIFEs1R6ORpZYWHIXGR6bHC1qijpyL4Sj6DEZjZjsSZqmYaxK1ORcvlc-ZqSoyNKwnRpGTyK4WDK5BQ6BQ5BRm3EW55uG1K0n9ClUqgqgFuxketJe7nIv2rUNB0x7LmSL2qGMsSySevcmSJhzJgnipWQOgEma510M4HmcqHZYyWqaOMqTQyWGh0osVSGiwC5uGyftx74sWvHuBNMhX7O-5DoHiPae72lvnlwPBydFlRVS7qPIl7cilP74-+SByMMKBkB4ZKoL4cikgAbigADWYByDA+AACJJgQg4xPmI7FHkZQrKGsjqKcCiaMG9YpJOxySBiCiyPoX6dnuRJ-gEgHAaBmaUm4XDDBQABm1BYIhYAoWhyqnrSmHDpeCAKCicjUbU6g6nkFichYsJrLWVxaPsk7KdICZCmJlqEraAFASBvbPAOEmqlJF4JJURbVDcy4Yvk1GVkUsabApMjKZGqjNg2kgMU8Xa-j0FnsQBXBUJ4vRgH2DBOhEkn0o5TLKV6y6WDG6lhkYVYIDoKzyBkeR8pUDZqOFu5WuZEBsVZzUeFQ+AmDQsAYAARlgAgYZl7o6I2tYLJINSSO+3JaMGlQpGkhFhryo2jW2xkdhFTFNS1EAAT1-UCHa4EIdBcEIYdA34AAKlQZC4LAZAksIsBDeqBbrdpym8iuByxlcLK5BYqQLBUZyTcFvL1aZ3YsTFrVyFdx0ZuSXGdDx-GCUjfXXXdD1PS9j3vVhMnrWCFRxtNaRLdcfIsiwuS5fkgZaOUlhpDDP7MdFzWWftzXI-gdrPGlLoOSNyiHFstRySisjcgzahyFoUYBbRsac5tO6w1F7wIwLONHfg0qyvKyVfPgVAmCT0kJGt41pJD02xgcpElUkcZ6rI+q5JcckbU0W0NWZB57QduMCKbcoKmIsCpXIZB8YwVAABRC-jj3PYCsA3XwOAoKQACUNDmttjVh-zEfG9H5u21lpVjSrTtTTNbsstUYJJAFWgA37XORTz+t8+xtcKpb1v1+6KJFopGQqRi6nBlstYcqNK5riusYDztlejzKMfJXHCdJynqd8SJaAABYAEpgFgKCMAAyrgZBcLAV+P3nBfF6XJnc7tfmY8xZnglgWGe-klILzUhYDSJVRpnCONNOcWxWRKBRDYO4uAUD7XgJEMuIdqDi2GgWQgOhgxMyRKyFc8IuQkXUDvK0HgvAHmIR9bCD4SoeSWCoLkoZpxrmXIw0OLEMxsNJgkSc418KhnrHyG4oZYTcPhMifhJx4SCiDjrABSpgHiLtogAUhwW77DRIGXkk55wexKCrJQsg1jBTnPsYRqZviiL6PohuORgyhhBhGKMsZYzxhcXrf8EBPHulUJOPCtRlABWIu7IoORVBIIhMpNYGJyghKHmEvaYjQEkOwhkxQrJtBES0JDOBPlkgKD1JYZSjZORyTXNkwBsVwkFPYTJVYS58JxPKbOYM0gUj7FjGcEMOpciaJxMHXWOTWJV2avFRKpIwARILJRGJBF4mZBIkDE0KtIxLSSDkDYGhWl70Ru1Tq6zsLURBkoLyWRmz8PmlUZmcY1zXDKdMghcy2mIyFh8W5ZN4RFmOFyKaZwiLeT2GVJcy5pBrguCiMK2tvyDwBYbIWejOkSMQBkeQORJq0RNCUDIDNondxuGpPQmRqIXPhiPECuKMpdMkbILZ-SEnLxyjqOJMZsj1jRTYIAA */\n\n  id: 'document-mutator',\n\n  context: ({input}) => ({\n    client: input.client.withConfig({allowReconfigure: false}),\n    sharedListener: input.sharedListener,\n    id: input.id,\n    remote: undefined,\n    local: undefined,\n    mutationEvents: [],\n    stagedChanges: [],\n    stashedChanges: [],\n    error: undefined,\n    fetchRemoteSnapshotAttempts: 0,\n    submitTransactionsAttempts: 0,\n    cache: input.cache,\n  }),\n\n  // Auto start the connection by default\n  entry: ['connect to server-sent events'],\n\n  on: {\n    mutate: {\n      actions: ['rebase local snapshot', 'stage mutation'],\n    },\n  },\n  initial: 'disconnected',\n  states: {\n    disconnected: {\n      on: {\n        connect: {\n          target: 'connecting',\n          actions: ['listen to server-sent events'],\n        },\n      },\n    },\n    connecting: {\n      on: {\n        welcome: 'connected',\n        reconnect: 'reconnecting',\n        error: 'connectFailure',\n      },\n      tags: ['busy'],\n    },\n    connectFailure: {\n      on: {\n        connect: {\n          target: 'connecting',\n          actions: ['listen to server-sent events'],\n        },\n      },\n      entry: [\n        'stop listening to server-sent events',\n        'assign error to context',\n      ],\n      exit: ['clear error from context'],\n      tags: ['error'],\n    },\n    reconnecting: {\n      on: {\n        welcome: {\n          target: 'connected',\n        },\n        error: {\n          target: 'connectFailure',\n        },\n      },\n      tags: ['busy', 'error'],\n    },\n    connected: {\n      on: {\n        mutation: {\n          actions: ['buffer remote mutation events'],\n        },\n        reconnect: 'reconnecting',\n      },\n      entry: ['clear error from context'],\n      initial: 'loading',\n      states: {\n        loading: {\n          invoke: {\n            src: 'fetch remote snapshot',\n            id: 'getDocument',\n            input: ({context}) => ({\n              client: context.client,\n              id: context.id,\n            }),\n            onError: {\n              target: 'loadFailure',\n            },\n            onDone: {\n              target: 'loaded',\n              actions: [\n                'rebase fetched remote snapshot',\n                'reset fetch attempts',\n              ],\n            },\n          },\n\n          tags: ['busy'],\n        },\n\n        loaded: {\n          entry: ['send sync event to parent'],\n          on: {\n            mutation: {\n              actions: ['apply mendoza patch', 'send mutation event to parent'],\n            },\n          },\n          initial: 'pristine',\n\n          states: {\n            pristine: {\n              on: {\n                mutate: {\n                  actions: ['rebase local snapshot', 'stage mutation'],\n                  target: 'dirty',\n                },\n              },\n              tags: ['ready'],\n            },\n            dirty: {\n              on: {\n                submit: 'submitting',\n              },\n              tags: ['ready'],\n            },\n            submitting: {\n              on: {\n                mutate: {\n                  actions: ['rebase local snapshot', 'stash mutation'],\n                },\n              },\n              invoke: {\n                src: 'submit mutations as transactions',\n                id: 'submitTransactions',\n                input: ({context}) => {\n                  // @TODO perhaps separate utils to be lower level and operate on single documents at a time instead of expecting a local dataset\n                  const remoteDataset = new Map()\n                  remoteDataset.set(context.id, context.remote)\n                  return {\n                    client: context.client,\n                    transactions: toTransactions(\n                      // Squashing DMP strings is the last thing we do before submitting\n                      squashDMPStrings(\n                        remoteDataset,\n                        squashMutationGroups(context.stagedChanges),\n                      ),\n                    ),\n                  }\n                },\n                onError: {\n                  target: 'submitFailure',\n                },\n\n                onDone: {\n                  target: 'pristine',\n                  actions: [\n                    'restore stashed changes',\n                    'reset submit attempts',\n                    'send pristine event to parent',\n                  ],\n                },\n              },\n              /**\n               * 'busy' means we should show a spinner, 'ready' means we can still accept mutations, they'll be applied optimistically right away, and queued for submissions after the current submission settles\n               */\n              tags: ['busy', 'ready'],\n            },\n            submitFailure: {\n              exit: ['clear error from context'],\n              after: {\n                submitTransactionsTimeout: {\n                  actions: ['increment submit attempts'],\n                  target: 'submitting',\n                },\n              },\n              on: {\n                retry: 'submitting',\n              },\n              /**\n               * How can it be both `ready` and `error`? `ready` means it can receive mutations, optimistically apply them, and queue them for submission. `error` means it failed to submit previously applied mutations.\n               * It's completely fine to keep queueing up more mutations and applying them optimistically, while showing UI that notifies that mutations didn't submit, and show a count down until the next automatic retry.\n               */\n              tags: ['error', 'ready'],\n            },\n          },\n        },\n\n        loadFailure: {\n          exit: ['clear error from context'],\n          after: {\n            fetchRemoteSnapshotTimeout: {\n              actions: ['increment fetch attempts'],\n              target: 'loading',\n            },\n          },\n          on: {\n            retry: 'loading',\n          },\n          tags: ['error'],\n        },\n      },\n    },\n  },\n})\n\nfunction applyMendozaPatch<const DocumentType extends SanityDocumentBase>(\n  document: DocumentType | undefined,\n  patch: RawPatch,\n  nextRevision: string | undefined,\n) {\n  const next = applyPatch(omitRev(document), patch)\n  if (!next) {\n    return null\n  }\n  return Object.assign(next, {_rev: nextRevision})\n}\n\nfunction omitRev<const DocumentType extends SanityDocumentBase>(\n  document: DocumentType | undefined,\n) {\n  if (!document) {\n    return null\n  }\n  // eslint-disable-next-line unused-imports/no-unused-vars\n  const {_rev, ...doc} = document\n  return doc\n}\n"],"names":["scopedUrlAlphabet","applyPatches","patch","stringifyPath","assign"],"mappings":";;;;;AAOO,SAAS,sBAAsB,UAAgC;AACpE,MAAI,SAAS,SAAS;AACpB,WAAO,SAAS;AAElB,MAAI,SAAS,SAAS;AACpB,WAAO,SAAS,SAAS;AAE3B,MAAI,SAAS,SAAS;AACpB,WAAO,SAAS;AAKlB,MAHI,SAAS,SAAS,uBAGlB,SAAS,SAAS;AACpB,WAAO,SAAS,SAAS;AAErB,QAAA,IAAI,MAAM,uBAAuB;AACzC;ACxBO,MAAM,cACX;ACmBK,IAAI,SAAS,CAAC,OAAO,OAAO;AACjC,MAAI,KAAK,IACL,QAAQ,OAAO,gBAAgB,IAAI,WAAW,IAAI,CAAC;AACvD,SAAO;AACL,UAAMA,YAAkB,MAAM,IAAI,IAAI,EAAE;AAE1C,SAAO;AACT;ACzBA,SAAS,iBAAoB,OAA2B,OAAkB;AACpE,MAAA,QAAQ,KAAK,SAAS,MAAM;AACxB,UAAA,IAAI,MAAM,qBAAqB;AAEvC,SAAO,MAAM,KAAK;AACpB;AAEgB,SAAA,WAAW,YAAkB,MAAqB;AAChE,SACE,WAAW,UAAU,KAAK,UAC1B,WAAW;AAAA,IAAM,CAAC,SAAS,MACzB,eAAe,SAAS,iBAAiB,MAAM,CAAC,CAAC;AAAA,EACnD;AAEJ;AAWgB,SAAA,eACd,UACA,UACS;AACT,SAAI,aAAa,QAAQ,KAAK,aAAa,QAAQ,IAC1C,SAAS,SAAS,SAAS,OAGhC,eAAe,QAAQ,IAClB,OAAO,QAAQ,MAAM,OAAO,QAAQ,IAGtC,aAAa;AACtB;AAEO,SAAS,aACd,SAC6B;AACtB,SAAA,OAAQ,SAAiB,QAAS;AAC3C;AACO,SAAS,eAAe,SAAyC;AACtE,SAAO,OAAO,WAAY;AAC5B;AAEO,SAAS,eACd,SAC6B;AAC7B,SACE,OAAO,WAAY,YACnB,UAAU,WACV,OAAO,QAAQ,QAAS;AAE5B;AACO,SAAS,eACd,SACsC;AACtC,SAAO,OAAO,WAAY,YAAY,eAAe,OAAO;AAC9D;AAEO,SAAS,kBAAkB,SAAyC;AACzE,SAAO,OAAO,WAAY;AAC5B;AC7BgB,SAAA,UAAU,MAAY,OAAyB;AAC7D,MAAI,KAAK,WAAW;AACX,WAAA;AAGT,MAAI,UAAU;AACd,aAAW,QAAQ,MAAM;AACnB,QAAA,eAAe,IAAI,GAAG;AACpB,UAAA,CAAC,MAAM,QAAQ,OAAO;AACxB;AAGE,UAAA,eAAe,IAAI,GAAG;AACxB,kBAAU,QAAQ,KAAK,CAAA,SAAQ,KAAK,SAAS,KAAK,IAAI;AACtD;AAAA,MAAA;AAEF,gBAAU,QAAQ,IAAI;AACtB;AAAA,IAAA;AAEF,cAAW,QAAgB,IAAI;AAAA,EAAA;AAE1B,SAAA;AACT;AC1DA,MAAM,cAAc;AAEpB,SAAS,iBAAiB,SAAsB,YAA6B;AAC3E,SAAI,MAAM,QAAQ,OAAO,IAChB,IAAI,QAAQ,CAAC,CAAC,IAAI,QAAQ,CAAC,KAAK,EAAE,MAE9B,OAAO,WAEM,WAGjB,IAAI,OAAO,MAGhB,eAAe,OAAO,IACjB,UAAU,KAAK,UAAU,QAAQ,IAAI,CAAC,MAG3C,OAAO,WAAY,YAAY,YAAY,KAAK,OAAO,IAClD,aAAa,UAAU,IAAI,OAAO,KAGpC,KAAK,OAAO;AACrB;AAEO,SAAS,UAAU,WAAyB;AACjD,SAAO,UACJ,IAAI,CAAC,SAAS,MAAM,iBAAiB,SAAS,MAAM,CAAC,CAAC,EACtD,KAAK,EAAE;AACZ;AChCO,SAAS,SAAS,KAEvB;AACO,SAAA,QAAQ,QAAQ,OAAO,OAAQ,YAAY,CAAC,MAAM,QAAQ,GAAG;AACtE;ACJO,SAAS,MAAM,OAA2B;AAE5C,SAAA,UAAU,QACT,OAAO,SAAU,YACjB,OAAO,MAAM,QAAS,YACtB,MAAM,QACR;AAEJ;ACLgB,SAAA,gBAAmB,OAAY,aAA0B;AACvE,MAAI,OAAO,eAAgB;AAClB,WAAA,eAAe,MAAM,QAAQ,WAAW;AAE7C,MAAA,eAAe,WAAW,GAAG;AACzB,UAAA,MAAM,MAAM,UAAU,CAAA,UAAS,MAAM,KAAK,MAAM,YAAY,IAAI;AAC/D,WAAA,QAAQ,KAAK,OAAO;AAAA,EAAA;AAE7B,QAAM,IAAI;AAAA,IACR,gHAAgH,KAAK;AAAA,MACnH;AAAA,IAAA,CACD;AAAA,EACH;AACF;AAEgB,SAAA,aAAa,UAA8B,OAAe;AACjE,SAAA,aAAa,WAAW,QAAQ,QAAQ;AACjD;AAIgB,SAAA,eAAe,QAAgB,OAAe;AAC5D,MAAI,WAAW,MAAM,UAAU,MAAM,UAAU;AACtC,WAAA;AAET,QAAM,aAAa,QAAQ,IAAI,SAAS,QAAQ;AAChD,SAAO,cAAc,UAAU,aAAa,IAAI,OAAO;AACzD;AAUO,SAAS,OACd,KACA,OACA,aACA,OACK;AACC,QAAA,OAAO,IAAI,MAAM;AACvB,SAAA,KAAK,OAAO,OAAO,aAAa,GAAI,SAAS,CAAG,CAAA,GACzC;AACT;ACtCgB,SAAA,OAGd,IAAO,cAA4B;AAC/B,MAAA,CAAC,MAAM,QAAQ,YAAY;AACvB,UAAA,IAAI,UAAU,4CAA4C;AAGlE,QAAM,QAAQ,gBAAgB,cAAc,GAAG,aAAa;AAC5D,MAAI,UAAU;AACZ,UAAM,IAAI,MAAM,6CAA6C,GAAG,QAAQ,EAAE;AAG5E,SAAI,aAAa,WAAW,IACnB,GAAG,QAEL,OAAO,cAAc,aAAa,GAAG,UAAU,KAAK,GAAG,GAAG,GAAG,KAAK;AAC3E;AAEgB,SAAA,OAGd,IAAO,cAA4B;AAC/B,MAAA,CAAC,MAAM,QAAQ,YAAY;AACvB,UAAA,IAAI,UAAU,4CAA4C;AAG9D,MAAA,GAAG,MAAM,WAAW;AACf,WAAA;AAET,QAAM,kBAA4B,IAC5B,cAAyB,CAAC;AAYhC,MAXA,GAAG,MAAM,QAAQ,CAAC,kBAAuB,MAAM;AAC7C,UAAM,gBAAgB,aAAa;AAAA,MACjC,CAAA,iBAAiB,cAAsB,SAAS,iBAAiB;AAAA,IACnE;AACI,qBAAiB,IACnB,gBAAgB,aAAa,IAAI,IAEjC,YAAY,KAAK,gBAAgB;AAAA,EAAA,CAEpC,GAEG,gBAAgB,WAAW,KAAK,YAAY,UAAU;AACjD,WAAA;AAGH,QAAA,OAAO,CAAC,GAAG,YAAY;AAE7B,aAAW,KAAK;AACd,SAAK,CAAC,IAAI,GAAG,MAAM,gBAAgB,CAAC,CAAE;AAIjC,SAAA;AAAA,IACL;AAAA,MACE,MAAM;AAAA,MACN,OAAO;AAAA,MACP,eAAe,GAAG;AAAA,MAClB,UAAU,GAAG;AAAA,IACf;AAAA,IACA;AAAA,EACF;AACF;AAEgB,SAAA,QAGd,IAAO,cAA4B;AAC/B,MAAA,CAAC,MAAM,QAAQ,YAAY;AACvB,UAAA,IAAI,UAAU,6CAA6C;AAGnE,QAAM,QAAQ,gBAAgB,cAAc,GAAG,aAAa;AAC5D,MAAI,UAAU;AACN,UAAA,IAAI,MAAM,4CAA4C;AAE9D,SAAO,OAAO,cAAc,OAAO,GAAG,MAAM,QAAQ,GAAG,KAAK;AAC9D;AACgB,SAAA,OAGd,IAAO,cAA4B;AAC/B,MAAA,CAAC,MAAM,QAAQ,YAAY;AACvB,UAAA,IAAI,UAAU,4CAA4C;AAGlE,QAAM,QAAQ,gBAAgB,cAAc,GAAG,aAAa;AAC5D,MAAI,UAAU;AACN,UAAA,IAAI,MAAM,4CAA4C;AAE9D,SAAO,OAAO,cAAc,OAAO,GAAG,CAAA,CAAE;AAC1C;AAEgB,SAAA,SACd,IACA,cACA;AACI,MAAA,CAAC,MAAM,QAAQ,YAAY;AACvB,UAAA,IAAI,UAAU,8CAA8C;AAG7D,SAAA,OAAO,GAAG,YAAa,WAC1B,aACG,MAAM,GAAG,GAAG,UAAU,EACtB,OAAO,aAAa,MAAM,GAAG,QAAQ,CAAC,IACzC,aAAa,MAAM,GAAG,GAAG,UAAU;AACzC;AChHgB,SAAA,IACd,IACA,cACA;AACA,SAAO,GAAG;AACZ;AAEgB,SAAA,aACd,IACA,cACA;AACA,SAAO,gBAAgB,GAAG;AAC5B;AAEO,SAAS,MAAuC,IAAO;AAE9D;ACpBgB,SAAA,IACd,IACA,cACA;AACA,MAAI,OAAO,gBAAiB;AACpB,UAAA,IAAI,UAAU,2CAA2C;AAGjE,SAAO,eAAe,GAAG;AAC3B;AAEgB,SAAA,IACd,IACA,cACA;AACA,MAAI,OAAO,gBAAiB;AACpB,UAAA,IAAI,UAAU,2CAA2C;AAGjE,SAAO,eAAe,GAAG;AAC3B;ACtBO,MAAM,SAAS,OAAO,UAAU,eAAe,KAAK;AAAA,EACzD,OAAO,UAAU;AACnB;ACAO,SAAS,QAAQ,GAAW;AACjC,aAAW,OAAO;AACZ,QAAA,OAAO,GAAG,GAAG;AACR,aAAA;AAGJ,SAAA;AACT;ACTgB,SAAA,KAA2B,KAAQ,OAAwB;AACnE,QAAA,OAAO,EAAC,GAAG,IAAG;AACpB,aAAW,QAAQ;AACjB,WAAO,KAAK,IAAI;AAEX,SAAA;AACT;ACEgB,SAAA,SACd,IACA,cACA;AACI,MAAA,CAAC,SAAS,YAAY;AAClB,UAAA,IAAI,UAAU,+CAA+C;AAG9D,SAAA,GAAG,KAAK,WAAW,IACtB,eACA,KAAK,cAAc,GAAG,IAAa;AACzC;AAEgB,SAAA,OAAyB,IAAiB,cAAiB;AACrE,MAAA,CAAC,SAAS,YAAY;AAClB,UAAA,IAAI,UAAU,6CAA6C;AAG5D,SAAA,QAAQ,GAAG,KAAK,IAAI,eAAe,EAAC,GAAG,cAAc,GAAG,GAAG,MAAK;AACzE;ACvBgB,SAAA,eAGd,IAAO,cAA4B;AACnC,MAAI,OAAO,gBAAiB;AACpB,UAAA,IAAI,UAAU,qDAAqD;AAG3E,SAAOC,eAAa,WAAW,GAAG,KAAK,GAAG,YAAY,EAAE,CAAC;AAC3D;;;;;;;;;;;;;;;;;ACmBgB,SAAA,QACd,IACA,cAC2B;AACvB,MAAA,EAAE,GAAG,QAAQ;AACf,UAAM,IAAI,MAAM,4BAA4B,GAAG,IAAI,GAAG;AAGxD,SAAQ,WAAW,GAAG,IAAI,EAAuB,IAAI,YAAY;AACnE;AC3BgB,SAAA,aACd,SACA,UACoD;AACpD,SAAQ,QAAwB;AAAA,IAC9B,CAAC,MAAMC,WAAU,eAAeA,QAAO,IAAI;AAAA,IAC3C;AAAA,EACF;AACF;AAEgB,SAAA,eACdA,QACA,UAC4B;AAC5B,SAAO,YAAYA,OAAM,MAAMA,OAAM,IAAI,QAAQ;AACnD;AAEA,SAAS,YACP,MACA,IACA,OACsB;AAClB,MAAA,CAAC,gBAAgB,IAAI;AAChB,WAAA,QAAQ,IAAW,KAAK;AAGjC,QAAM,CAAC,MAAM,GAAG,IAAI,IAAI;AAExB,MAAI,eAAe,IAAI,KAAK,MAAM,QAAQ,KAAK;AAC7C,WAAO,aAAa,MAAM,MAAM,IAAI,KAAK;AAG3C,MAAI,kBAAkB,IAAI,KAAK,SAAS,KAAK;AAC3C,WAAO,cAAc,MAAM,MAAM,IAAI,KAAK;AAG5C,QAAM,IAAI;AAAA,IACR,mCAAmC,GAAG,IAAI,aAAa;AAAA,MACrD;AAAA,IAAA,CACD,OAAO,OAAO,KAAK;AAAA,EACtB;AACF;AAEA,SAAS,cACP,MACA,MACA,IACA,QACA;AACM,QAAA,UAAU,OAAO,IAAI;AAEvB,MAAA,YAAY,UAAa,KAAK,SAAS;AAClC,WAAA;AAKT,QAAM,eAAe,YAAY,MAAM,IAAI,OAAO;AAK3C,SAAA,iBAAiB,UAAU,SAAS,EAAC,GAAG,QAAQ,CAAC,IAAI,GAAG,aAAY;AAC7E;AAEA,SAAS,aACP,MACA,MACA,IACA,OACA;AACM,QAAA,QAAQ,gBAAgB,OAAO,IAAK;AAEtC,MAAA,UAAU,QAOV,UAAU;AACL,WAAA;AAGH,QAAA,UAAU,MAAM,KAAK,GAIrB,cAAc,YAAY,MAAM,IAAI,OAAO;AAK1C,SAAA,gBAAgB,UACnB,QACA,OAAO,OAAO,OAAO,GAAG,CAAC,WAAW,CAAC;AAC3C;AAEA,SAAS,gBAAmB,GAAyC;AACnE,SAAO,EAAE,SAAS;AACpB;ACrGgB,SAAA,mBAGd,UAAoB,UAAkD;AACtE,MACE,SAAS,SAAS,cAClB,SAAS,SAAS,SAAS,QAAQ;AAE7B,UAAA,IAAI,MAAM,mBAAmB;AAEjC,MAAA,SAAS,OAAO,SAAS;AAC3B,UAAM,IAAI;AAAA,MACR,0EAA0E,SAAS,EAAE,oCAAoC,SAAS,GAAG;AAAA,IACvI;AAEK,SAAA,aAAa,SAAS,SAAS,QAAQ;AAChD;AC1BO,SAAS,MAAM,KAAgD;AACpE,SAAO,SAAS;AAClB;AACgB,SAAA,SACd,KACA,YACqB;AACd,SAAA,MAAM,GAAG,IAAI,MAAM,EAAC,GAAG,KAAK,KAAK,aAAY;AACtD;ACiCgB,SAAA,SACd,SACA,UACiB;AACjB,SAAO,SAAS,OAAO,CAAC,KAAK,MAAM;AAC3B,UAAA,MAAM,sBAAsB,KAAK,CAAC;AACxC,QAAI,IAAI,WAAW;AACX,YAAA,IAAI,MAAM,IAAI,OAAO;AAE7B,WAAO,IAAI,WAAW,SAAS,MAAM,IAAI;AAAA,KACxC,OAAO;AACZ;AAOgB,SAAA,sBACd,UACA,UACqB;AACrB,MAAI,SAAS,SAAS;AACb,WAAA,OAAO,UAAU,QAAQ;AAElC,MAAI,SAAS,SAAS;AACb,WAAA,kBAAkB,UAAU,QAAQ;AAE7C,MAAI,SAAS,SAAS;AACb,WAAA,IAAI,UAAU,QAAQ;AAE/B,MAAI,SAAS,SAAS;AACb,WAAA,gBAAgB,UAAU,QAAQ;AAE3C,MAAI,SAAS,SAAS;AACb,WAAA,MAAM,UAAU,QAAQ;AAGjC,QAAM,IAAI,MAAM,0BAA0B,SAAS,IAAI,EAAE;AAC3D;AAEA,SAAS,OACP,UACA,UACqB;AACjB,MAAA;AACF,WAAO,EAAC,QAAQ,SAAS,SAAS,yBAAwB;AAE5D,QAAM,SAAS,SAAS,SAAS,UAAU,MAAM;AACjD,SAAO,EAAC,QAAQ,WAAW,IAAI,OAAO,KAAK,OAAO,OAAM;AAC1D;AAEA,SAAS,kBACP,UACA,UACqB;AACrB,SAAK,MAAM,SAAS,QAAQ,IAMrB,WACH,EAAC,QAAQ,WACT,EAAC,QAAQ,WAAW,IAAI,SAAS,SAAS,KAAK,OAAO,SAAS,aAP1D;AAAA,IACL,QAAQ;AAAA,IACR,SAAS;AAAA,EACX;AAKJ;AAEA,SAAS,gBACP,UACA,UACqB;AACrB,SAAK,MAAM,SAAS,QAAQ,IAOrB,WACH;AAAA,IACE,QAAQ;AAAA,IACR,IAAI,SAAS,SAAS;AAAA,IACtB,QAAQ;AAAA,IACR,OAAO,SAAS;AAAA,EAClB,IACA,EAAC,QAAQ,WAAW,IAAI,SAAS,SAAS,KAAK,OAAO,SAAS,aAb1D;AAAA,IACL,QAAQ;AAAA,IACR,SAAS;AAAA,EACX;AAWJ;AAEA,SAAS,IACP,UACA,UACqB;AAChB,SAAA,WAGD,SAAS,OAAO,SAAS,MACpB,EAAC,QAAQ,SAAS,SAAS,8CAE7B;AAAA,IACL,QAAQ;AAAA,IACR,IAAI,SAAS;AAAA,IACb,QAAQ;AAAA,IACR,OAAO;AAAA,EAAA,IATA,EAAC,QAAQ,OAAM;AAW1B;AAEA,SAAS,MACP,UACA,UACqB;AACrB,MAAI,CAAC;AACI,WAAA;AAAA,MACL,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAEI,QAAA,OAAO,mBAAmB,UAAU,QAAQ;AAClD,SAAO,aAAa,OAChB,EAAC,QAAQ,WACT,EAAC,QAAQ,WAAW,IAAI,SAAS,IAAI,QAAQ,UAAU,OAAO,KAAI;AACxE;ACrJgB,SAAA,eACd,WACA,SACmB;AACb,QAAA,cAOK,uBAAA,OAAO,IAAI;AAEtB,aAAW,YAAY,WAAW;AAC1B,UAAA,aAAa,sBAAsB,QAAQ;AACjD,QAAI,CAAC;AACG,YAAA,IAAI,MAAM,yCAAyC;AAG3D,UAAM,SAAS,YAAY,UAAU,GAAG,SAAS,QAAQ,IAAI,UAAU,GACjE,MAAM,sBAAsB,QAAQ,QAAQ;AAClD,QAAI,IAAI,WAAW;AACX,YAAA,IAAI,MAAM,IAAI,OAAO;AAEzB,QAAI,WAAW,WAIjB,IAAI,WAAW,aACf,IAAI,WAAW,aACf,IAAI,WAAW,eAET,cAAc,gBAClB,YAAY,UAAU,IAAI,EAAC,QAAQ,OAAO,QAAW,MAAM,CAAC,EAAA,IAE9D,YAAY,UAAU,EAAG,QAAQ,IAAI;AAAA,EAAA;AAIlC,SAAA,OAAO,QAAQ,WAAW,EAAE;AAAA;AAAA,IAEjC,CAAC,CAAC,IAAI,EAAC,QAAQ,OAAO,KAAK,CAAA,OAClB;AAAA,MACL;AAAA,MACA,QAAQ,QAAS,SAAS,YAAY,YAAa;AAAA,MACnD,WAAW;AAAA,MACX;AAAA,MACA;AAAA,IACF;AAAA,EAEJ;AACF;AC9DgB,SAAA,OACd,SACA,SACA;AACA,UAAQ,QAAQ,CAAU,WAAA;AACxB,KAAI,OAAO,WAAW,aAAa,OAAO,WAAW,cACnD,QAAQ,IAAI,OAAO,IAAI,OAAO,KAAK,GAEjC,OAAO,WAAW,aACpB,QAAQ,OAAO,OAAO,EAAE;AAAA,EAAA,CAE3B;AACH;ACEgB,SAAA,eACd,KACA,WACA,MACA;AACA,QAAM,SAAS,CAAC;AAChB,aAAW,QAAQ,IAAI,MAAM,EAAE,WAAW;AACxC,QAAI,UAAU,IAAI;AAChB,aAGO;AAET,WAAO,KAAK,IAAI;AAAA,EAAA;AAElB,SAAO,OAAO,QAAQ;AACxB;AC1BA,SAAS,YAAY,IAAU,IAAU;AACvC,SAAO,UAAU,EAAE,MAAM,UAAU,EAAE;AACvC;AAEA,SAAS,WAAW,OAAkB,SAAoB;AAErD,UAAA,QAAQ,SAAS,SAAS,QAAQ,SAAS,aAC3C,MAAM,SAAS,SAAS,MAAM,SAAS;AAE5C;AAEO,SAAS,kBAAkB,SAAsB;AAC/C,SAAA;AAAA,IACL,kBAAkB,oBAAoB,OAAO,CAAC;AAAA,EAChD;AACF;AAEO,SAAS,oBAAoB,SAAsB;AACxD,SAAO,QAAQ;AAAA,IACb,CAAC,gBAA6B,eAA0B;AAClD,UAAA,WAAW,GAAG,SAAS;AACV,eAAA,eAAA,KAAK,UAAU,GACvB;AAGT,YAAM,aAAa,eAAe;AAAA,QAChC,kBAAgB,CAAC,WAAW,WAAW,MAAM,aAAa,IAAI;AAAA,MAChE;AACW,aAAA,WAAA,KAAK,UAAU,GACnB;AAAA,IACT;AAAA,IACA,CAAA;AAAA,EACF;AACF;AAEO,SAAS,kBAAkB,SAAsB;AACtD,SAAO,QAAQ;AAAA,IACb,CAAC,cAA2B,kBACN,aAAa;AAAA,MAC/B,CAAA,UACE,WAAW,MAAM,IAAI,aAAa,EAAE,KACpC,YAAY,MAAM,MAAM,aAAa,IAAI;AAAA,IAM7C,KAAA,aAAa,QAAQ,YAAY,GAC1B;AAAA,IAET,CAAA;AAAA,EACF;AACF;AAEO,SAAS,2BAA2B,SAAsB;AAC/D,SAAO,QAAQ;AAAA,IACb,CAAC,iBAA8B,eACzB,WAAW,GAAG,SAAS,kBACzB,gBAAgB,KAAK,UAAU,GACxB,oBAGK;AAAA,MACZ;AAAA,MACA,CAAAA,WAASA,OAAM,GAAG,SAAS;AAAA,IAAA,EAEL;AAAA,MACtB,CAAA,mBACE,eAAe,GAAG,SAAS,kBAC3B,YAAY,eAAe,MAAM,WAAW,IAAI;AAAA,IAMpD,KAAA,gBAAgB,KAAK,UAAU,GACxB;AAAA,IAET,CAAA;AAAA,EACF;AACF;AAEgB,SAAA,qBACd,MACA,SACA;AACA,MAAI,OAAO;AACX,SAAO,QAAQ;AAAA,IACb,CAAC,gBAA6B,eAA0B;AACtD,YAAM,SAAS;AAEf,UADA,OAAO,eAAe,YAAY,IAAI,GAEpC,WAAW,GAAG,SAAS,SACvB,OAAO,WAAW,GAAG,SAAU,UAC/B;AACA,cAAM,UAAU,UAAU,WAAW,MAAM,MAAM;AAC7C,YAAA,OAAO,WAAY,UAAU;AAE/B,gBAAM,WAAsB;AAAA,YAC1B,GAAG;AAAA,YACH,IAAI;AAAA,cACF,MAAM;AAAA,cACN,OAAO;AAAA,gBACL,YAAY,SAAS,WAAW,GAAG,KAAK;AAAA,cAAA;AAAA,YAC1C;AAAA,UAEJ;AACA,iBAAO,eACJ,QAAQ,CAAA,OACA,YAAY,GAAG,MAAM,WAAW,IAAI,KACzC,GAAG,GAAG,SAAS,mBACb,KACA,EACL,EACA,OAAO,QAAQ;AAAA,QAAA;AAAA,MACpB;AAEa,aAAA,eAAA,KAAK,UAAU,GACvB;AAAA,IACT;AAAA,IACA,CAAA;AAAA,EACF;AACF;ACtHgB,SAAA,iBACd,QACA,gBACiB;AACV,SAAA,eAAe,IAAI,CAAkB,mBAAA;AAAA,IAC1C,GAAG;AAAA,IACH,WAAW,gBAAgB,QAAQ,cAAc,SAAS;AAAA,EAAA,EAC1D;AACJ;AAEgB,SAAA,gBACd,OACA,WACY;AACZ,SAAO,UAAU,IAAI,CAAC,UAAU,MACvB,SAAS,SAAS,UACrB,oBAAoB,MAAM,IAAI,SAAS,EAAE,GAAG,QAAQ,IACpD,QACL;AACH;AAEgB,SAAA,oBACd,MACA,UACe;AACf,SAAK,OAGE;AAAA,IACL,GAAG;AAAA,IACH,SAAS,qBAAqB,MAAM,SAAS,OAAsB;AAAA,EAAA,IAJ5D;AAMX;ACtCO,SAAS,oBACd,gBACiB;AACjB,SAAO,WAAW,gBAAgB,CAAA,UAAS,CAAC,MAAM,WAAW,EAAE;AAAA,IAC7D,CAAU,WAAA;AAAA,MACR,GAAG,MAAM,CAAC;AAAA,MACV,WAAW,MAAM,QAAQ,CAAA,MAAK,EAAE,SAAS;AAAA,IAC3C;AAAA,EACF;AACF;AAOgB,SAAA,WACd,KACA,WACO;AACP,QAAM,MAAa,CAAC;AACpB,MAAI,eAAoB,CAAC;AACzB,SAAA,IAAI,QAAQ,CAAQ,SAAA;AACd,cAAU,IAAI,IAChB,aAAa,KAAK,IAAI,KAElB,aAAa,SAAS,KACxB,IAAI,KAAK,YAAY,GAEvB,eAAe,CAAA,GACf,IAAI,KAAK,CAAC,IAAI,CAAC;AAAA,EAAA,CAElB,GACG,aAAa,SAAS,KACxB,IAAI,KAAK,YAAY,GAEhB;AACT;AClCO,SAAS,qBAAqB,QAA0C;AAC7E,SAAO,oBAAoB,MAAM,EAC9B,IAAI,CAAgB,iBAAA;AAAA,IACnB,GAAG;AAAA,IACH,WAAW,gBAAgB,YAAY,SAAS;AAAA,EAAA,EAChD,EACD,IAAI,CAAgB,iBAAA;AAAA,IACnB,GAAG;AAAA,IACH,WAAW,YAAY,UAAU,IAAI,cAC/B,SAAS,SAAS,UACb,WAEF;AAAA,MACL,GAAG;AAAA,MACH,SAAS,kBAAkB,SAAS,OAAsB;AAAA,IAE7D,CAAA;AAAA,EAAA,EACD;AACN;AAQO,SAAS,gBAAgB,WAAmC;AAC3D,QAAA,aAAa,QAAQ,WAAW,qBAAqB;AAC3D,SAAO,OAAO,OAAO,UAAU,EAAE,QAAQ,uBAEhC,wBAAwB,aAAa,iBAA0B,CAAC,EACpE,KAAK,EACL,OAAO,CAAC,KAAiB,gBAAgB;AACxC,UAAM,OAAO,IAAI,IAAI,SAAS,CAAC;AAC/B,YAAK,CAAC,QAAQ,KAAK,SAAS,YAAY,YAAY,SAAS,UACpD,IAAI,MAAM,GAAG,EAAE,EAAE,OAAO;AAAA,MAC7B,GAAG;AAAA,MACH,UAAU,MAAM,WAAW,CAAA,GAAI,OAAO,YAAY,OAAO;AAAA,IAAA,CAC1D,IAEI,IAAI,OAAO,WAAW;AAAA,EAC/B,GAAG,CAAE,CAAA,CACR;AACH;AAMO,SAAS,wBAAwB,WAAmC;AACrE,SAAA,UAAU,WAAW,IAChB,YAGF,UAAU,OAAO,CAAC,cAA0B,aAC7C,SAAS,SAAS,uBACpB,aAAa,KAAK,QAAQ,GACnB,iBAEI,eAAe,cAAc,CAAK,MAAA,EAAE,SAAS,QAAQ,EAC3C;AAAA,IACrB,CAAA,mBAAkB,eAAe,SAAS;AAAA,EAAA,KAM5C,aAAa,KAAK,QAAQ,GACnB,eACN,CAAA,CAAE;AACP;AAEA,SAAS,aAAa,WAAmC;AACnD,SAAA,UAAU,WAAW,IAChB,YAGF,UAAU,OAAO,CAAC,cAA0B,aAC7C,SAAS,SAAS,WACb,CAAC,QAAQ,KAElB,aAAa,KAAK,QAAQ,GACnB,eACN,EAAE;AACP;AC3DO,SAAS,OACd,YACA,SACA,SACA,iBACsE;AAMtE,MAAI,OAAO;AACL,QAAA,WAAW,gBAAgB,IAAI,CAAe,gBAAA;AAClD,UAAM,YAAY,YAAY,UAAU,QAAQ,CAAO,QAAA;AACjD,UAAA,sBAAsB,GAAG,MAAM;AACjC,eAAO,CAAC;AAEV,YAAM,SAAS;AAKf,aAJA,OAAO,SAAS,MAAM,CAAC,GAAG,CAAC,GACvB,CAAC,UAGD,IAAI,SAAS,UACR,MAEF;AAAA,QACL,MAAM;AAAA,QACN,UAAU;AAAA,UACR,GAAG;AAAA;AAAA;AAAA,UAGH,YAAY,qBAAqB,QAAQ,IAAI,OAAsB;AAAA,UACnE,UAAU,IAAI;AAAA,QAAA;AAAA,MAElB;AAAA,IAAA,CACD;AACM,WAAA,EAAC,GAAG,aAAa,UAAS;AAAA,EAAA,CAClC;AAED,MAAI,kCAAkE;AAG/C,kBAAS,IAAI,CAAe,gBAAA;AACjD,UAAM,UAAU,CAAC;AACV,WAAA,YAAY,UAAU,QAAQ,CAAO,QAAA;AAC1C,UAAI,IAAI,SAAS;AAEX,YAAA;AACgC,4CAAA;AAAA,YAChC,IAAI,SAAS;AAAA,YACb;AAAA,UAAA,GAEF,QAAQ,KAAK,GAAG;AAAA,QAAA,QACJ;AAEZ,kBAAQ,KAAK,qDAAqD;AAC9D,cAAA;AACgC,8CAAA;AAAA,cAChC,IAAI,SAAS;AAAA,cACb;AAAA,YAAA,GAEF,QAAQ,KAAK,GAAG;AAAA,mBACT,QAAa;AACpB,kBAAM,IAAI;AAAA,cACR,uCAAuC,UAAU,MAAM,OAAO,OAAO;AAAA,YACvE;AAAA,UAAA;AAAA,QACF;AAAA;AAGgC,0CAAA;AAAA,UAChC;AAAA,UACA,CAAC,GAAG;AAAA,QACN;AAAA,IAAA,CAEH;AAAA,EACF,CAAA,GA4BM,CA1BU,gBAAgB,IAAI,CAAC,iBAE7B;AAAA,IACL,GAAG;AAAA,IACH,WAAW,YAAY,UAAU,IAAI,CAC/B,QAAA,IAAI,SAAS,WAAW,sBAAsB,GAAG,MAAM,aAClD,MAEF;AAAA,MACL,GAAG;AAAA,MACH,SAAS,IAAI,QAAQ,IAAI,YACnBA,OAAM,GAAG,SAAS,QACbA,SAEF;AAAA,QACL,GAAGA;AAAA,QACH,IAAI;AAAA,UACF,GAAGA,OAAM;AAAA,UACT,OAAO,UAAUA,OAAM,MAAM,+BAA+B;AAAA,QAAA;AAAA,MAGjE,CAAA;AAAA,IAEJ,CAAA;AAAA,EAAA,EAEJ,GACiB,+BAA+B;AACnD;ACvIO,SAAS,eAAe,QAAwC;AAC9D,SAAA,OAAO,IAAI,CACZ,UAAA,MAAM,eAAe,MAAM,OAAO,SAC7B,EAAC,IAAI,MAAM,IAAK,WAAW,MAAM,UAAS,IAE5C,EAAC,WAAW,MAAM,WAC1B;AACH;ACHO,SAAS,OAAO,UAAoB;AACzC,SAAO,eAAe,QAAQ;AAChC;AAEO,SAAS,UAAU,WAAuB;AACxC,SAAA,UAAU,QAAQ,MAAM;AACjC;AAEO,SAAS,kBAAkB,aAA0B;AACnD,SAAA;AAAA,IACL,eAAe,YAAY;AAAA,IAC3B,WAAW,UAAU,YAAY,SAAS;AAAA,EAC5C;AACF;AAEO,SAAS,eAAe,UAAoB;AACjD,MACE,SAAS,SAAS,YAClB,SAAS,SAAS,uBAClB,SAAS,SAAS;AAElB,WAAO,EAAC,CAAC,SAAS,IAAI,GAAG,SAAS,SAAQ;AAE5C,MAAI,SAAS,SAAS;AACb,WAAA;AAAA,MACL,QAAQ,EAAC,IAAI,SAAS,GAAE;AAAA,IAC1B;AAEI,QAAA,eAAe,SAAS,SAAS;AAChC,SAAA,SAAS,QAAQ,IAAI,CACnBA,YAAA;AAAA,IACL,OAAO;AAAA,MACL,IAAI,SAAS;AAAA,MACb,GAAI,gBAAgB,EAAC,aAAY;AAAA,MACjC,GAAG,cAAcA,MAAK;AAAA,IAAA;AAAA,EACxB,EAEH;AACH;AAEA,SAAS,cAAcA,QAAkB;AACjC,QAAA,EAAC,MAAM,GAAA,IAAMA;AACnB,MAAI,GAAG,SAAS;AACd,WAAO,EAAC,OAAO,CAACC,UAAc,IAAI,CAAC,EAAC;AAEtC,MAAI,GAAG,SAAS;AACP,WAAA;AAAA,MACL,QAAQ;AAAA,QACN,CAAC,GAAG,QAAQ,GAAGA,UAAc,CAAC,GAAG,MAAM,GAAG,aAAa,CAAC;AAAA,QACxD,OAAO,GAAG;AAAA,MAAA;AAAA,IAEd;AAEF,MAAI,GAAG,SAAS;AACP,WAAA,EAAC,gBAAgB,EAAC,CAACA,UAAc,IAAI,CAAC,GAAG,GAAG,QAAM;AAE3D,MAAI,GAAG,SAAS;AACP,WAAA,EAAC,KAAK,EAAC,CAACA,UAAc,IAAI,CAAC,GAAG,GAAG,SAAO;AAEjD,MAAI,GAAG,SAAS;AACP,WAAA,EAAC,KAAK,EAAC,CAACA,UAAc,IAAI,CAAC,GAAG,GAAG,SAAO;AAEjD,MAAI,GAAG,SAAS,SAAS,GAAG,SAAS;AACnC,WAAO,EAAC,CAAC,GAAG,IAAI,GAAG,EAAC,CAACA,UAAc,IAAI,CAAC,GAAG,GAAG,QAAM;AAElD,MAAA,GAAG,SAAS,YAAY;AAC1B,UAAM,QAAQ;AAAA,MACZ,GAAG;AAAA,MACH,OAAO,GAAG,YAAa,WAAW,GAAG,WAAW;AAAA,IAAA,EAChD,KAAK,GAAG;AAEH,WAAA,EAAC,OAAO,CAAC,GAAGA,UAAc,IAAI,CAAC,IAAI,KAAK,GAAG,EAAC;AAAA,EAAA;AAErD,MAAI,GAAG,SAAS;AAEP,WAAA;AAAA,MACL,OAAO,GAAG,MAAM;AAAA,QAAI,CAAA,SAClBA,UAAc,CAAC,GAAG,MAAM,EAAC,MAAO,KAAa,MAAK,CAAC;AAAA,MACrD;AAAA,MACA,QAAQ;AAAA,QACN,CAAC,GAAG,QAAQ,GAAGA,UAAc,CAAC,GAAG,MAAM,GAAG,aAAa,CAAC;AAAA,QACxD,OAAO,GAAG;AAAA,MAAA;AAAA,IAEd;AAEF,MAAI,GAAG,SAAS;AACP,WAAA;AAAA,MACL,KAAK,OAAO;AAAA,QACV,OAAO,KAAK,GAAG,KAAK,EAAE,IAAI,CAAO,QAAA;AAAA,UAC/BA,UAAc,KAAK,OAAO,GAAG,CAAC;AAAA,UAC9B,GAAG,MAAM,GAA4B;AAAA,QACtC,CAAA;AAAA,MAAA;AAAA,IAEL;AAEF,MAAI,GAAG,SAAS;AACP,WAAA;AAAA,MACL,OAAO,GAAG,KAAK,IAAI,CAAA,QAAOA,UAAc,KAAK,OAAO,GAAG,CAAC,CAAC;AAAA,IAC3D;AAEF,MAAI,GAAG,SAAS;AACP,WAAA;AAAA,MACL,QAAQ;AAAA,QACN,SAASA,UAAc,KAAK,OAAO,GAAG,aAAa,CAAC;AAAA,QACpD,OAAO,GAAG;AAAA,MAAA;AAAA,IAEd;AAEF,MAAI,GAAG,SAAS;AACP,WAAA;AAAA,MACL,OAAO,CAACA,UAAc,KAAK,OAAO,GAAG,aAAa,CAAC,CAAC;AAAA,IACtD;AAGF,QAAM,IAAI,MAAM,0BAA0B,GAAG,IAAI,EAAE;AACrD;AC/GO,SAAS,qBAAqB,QAAsB;AACzD,QAAM,aAAa,OAChB;AAAA,IACC;AAAA,IACA,CAAC;AAAA,IACD;AAAA,MACE,QAAQ,CAAC,WAAW,YAAY,WAAW;AAAA,MAC3C,eAAe;AAAA,MACf,yBAAyB;AAAA,MACzB,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,kBAAkB;AAAA,IAAA;AAAA,EACpB,EAED,KAAK,MAAM,EAAC,qBAAqB,IAAK,CAAC,GAGpC,YAAY,WAAW;AAAA,IAC3B,OAAO,CAAC,UAAmC,MAAM,SAAS,WAAW;AAAA,EAAA,GAIjE,UAAU,WAAW;AAAA,IACzB,OAAO,CAAC,UAAiC,MAAM,SAAS,SAAS;AAAA,EAAA,GAI7D,YAAY,WAAW;AAAA,IAC3B,OAAO,CAAC,UAAkC,MAAM,SAAS,UAAU;AAAA,EAU/D,GAAA,gBANkB,MAAM,SAAS,SAAS,EAAE;AAAA,IAChD,YAAY,EAAC,YAAY,GAAG,UAAU,GAAK,CAAA;AAAA,EAAA,EAKP;AAAA,IACpC,OAAO,CAAA,0BAAyB,sBAAsB,SAAS,SAAS;AAAA,EAC1E;AAGO,SAAA,MAAM,eAAe,WAAW,SAAS;AAClD;ACCO,MAAM,yBAAyB,MAAM;AAAA,EAC1C,OAAO,CAAC;AAAA,EAkDR,SAAS;AAAA,IACP,2BAA2BC,SAAO,EAAC,OAAO,CAAC,EAAC,MAAA,MAAW,OAAM;AAAA,IAC7D,4BAA4BA,SAAO,EAAC,OAAO,QAAU;AAAA,IACrD,iCAAiC,MAAM,EAAC,MAAM,WAAU;AAAA,IACxD,gCAAgC,WAAW,sBAAsB;AAAA,MAC/D,IAAI;AAAA,MACJ,OAAO,CAAC,EAAC,eAAc;AAAA,QACrB,UACE,QAAQ,kBAAkB,qBAAqB,QAAQ,MAAM;AAAA,QAC/D,IAAI,QAAQ;AAAA,MACd;AAAA,IAAA,CACD;AAAA,IACD,wCAAwC,UAAU,UAAU;AAAA,IAC5D,iCAAiCA,SAAO;AAAA,MACtC,gBAAgB,CAAC,EAAC,OAAO,QACvB,OAAA,YAAY,OAAO,UAAU,GACtB,CAAC,GAAG,QAAQ,gBAAgB,KAAK;AAAA,IAAA,CAE3C;AAAA,IACD,2BAA2BA,SAAO;AAAA,MAChC,eAAe,CAAC,EAAC,OAAO,eACtB,YAAY,OAAO,sCAAsC,GAClD,QAAQ;AAAA,MAEjB,gBAAgB,CAAA;AAAA,IAAC,CAClB;AAAA,IACD,kCAAkC,eAAe,CAAC,EAAC,cAAa;AAC9D,cAAQ,OAAO,CAAC,EAAC,OAAO,cAAa;AACnC,oBAAY,OAAO,+BAA+B;AAClD,cAAM,iBAAiB,QAAQ;AAC3B,YAAA,aAAa,MAAM,QAMnB,iBAAiB;AACrB,mBAAWF,UAAS,QAAQ;AAExB,WAACA,OAAM,SAAS,SACf,CAACA,OAAM,eAAeA,OAAM,eAAe,aAG1C,CAAC,kBAAkBA,OAAM,gBAAgB,YAAY,SACvD,iBAAiB,KAEf,mBACF,aAAa;AAAA,YACX;AAAA,YACAA,OAAM,QAAQ;AAAA,YACdA,OAAM;AAAA,UAAA;AAMV,gBAAQ;AAAA,SAEP,CAAC,QAAQ,MAAM,IAAI,QAAQ,EAAE;AAAA,QAE5B,QAAQ,MAAM,IAAI,QAAQ,EAAE,EAAG,SAAS,YAAY,SAEtD,QAAQ,MAAM,IAAI,QAAQ,IAAI,UAA4B;AAGtD,cAAA,CAAC,eAAe,KAAK,IAAI;AAAA,UAC7B,QAAQ;AAAA;AAAA,UAER,mBAAmB,OAAO,SAAY;AAAA,UACtC,eAAe,OAAO,SAAa;AAAA,UACnC,QAAQ;AAAA,QACV;AAEO,eAAA;AAAA,UACL,QAAQ;AAAA,UACR;AAAA,UACA;AAAA;AAAA,UAEA,gBAAgB,CAAA;AAAA,QAClB;AAAA,MAAA,CACD,GACD,QAAQ;AAAA,QACN,CAAC,EAAC,QAAA,OACC;AAAA,UACC,MAAM;AAAA,UACN,IAAI,QAAQ;AAAA,UACZ,UAAU,QAAQ;AAAA,QACpB;AAAA,MACJ;AAAA,IAAA,CACD;AAAA,IACD,uBAAuBE,SAAO,CAAC,EAAC,OAAO,cAAa;AAClD,kBAAY,OAAO,UAAU;AAC7B,YAAM,iBAAiB,QAAQ;AAE3B,UAAA,MAAM,kBAAkB,gBAAgB;AAC1C,eAAO,CAAC;AAGV,YAAM,aAAa;AAAA,QACjB;AAAA,QACA,MAAM,QAAS;AAAA,QACf,MAAM;AAAA,MACR;AAGE,cAAQ;AAAA,OAEP,CAAC,QAAQ,MAAM,IAAI,QAAQ,EAAE;AAAA,MAE5B,QAAQ,MAAM,IAAI,QAAQ,EAAE,EAAG,SAAS,YAAY,SAEtD,QAAQ,MAAM,IAAI,QAAQ,IAAI,UAA4B;AAGtD,YAAA,CAAC,eAAe,KAAK,IAAI;AAAA,QAC7B,QAAQ;AAAA;AAAA,QAER,mBAAmB,OAAO,SAAY;AAAA,QACtC,eAAe,OAAO,SAAa;AAAA,QACnC,QAAQ;AAAA,MACV;AAEO,aAAA;AAAA,QACL,QAAQ;AAAA,QACR;AAAA,QACA;AAAA,MACF;AAAA,IAAA,CACD;AAAA,IACD,4BAA4BA,SAAO;AAAA,MACjC,6BAA6B,CAAC,EAAC,cAC7B,QAAQ,8BAA8B;AAAA,IAAA,CACzC;AAAA,IACD,wBAAwBA,SAAO;AAAA,MAC7B,6BAA6B;AAAA,IAAA,CAC9B;AAAA,IACD,6BAA6BA,SAAO;AAAA,MAClC,4BAA4B,CAAC,EAAC,cAC5B,QAAQ,6BAA6B;AAAA,IAAA,CACxC;AAAA,IACD,yBAAyBA,SAAO;AAAA,MAC9B,4BAA4B;AAAA,IAAA,CAC7B;AAAA,IACD,kBAAkBA,SAAO;AAAA,MACvB,eAAe,CAAC,EAAC,OAAO,QACtB,OAAA,YAAY,OAAO,QAAQ,GACpB;AAAA,QACL,GAAG,QAAQ;AAAA,QACX,EAAC,aAAa,IAAO,WAAW,MAAM,UAAS;AAAA,MACjD;AAAA,IAAA,CAEH;AAAA,IACD,kBAAkBA,SAAO;AAAA,MACvB,gBAAgB,CAAC,EAAC,OAAO,QACvB,OAAA,YAAY,OAAO,QAAQ,GACpB;AAAA,QACL,GAAG,QAAQ;AAAA,QACX,EAAC,aAAa,IAAO,WAAW,MAAM,UAAS;AAAA,MACjD;AAAA,IAAA,CAEH;AAAA,IACD,yBAAyB,eAAe,CAAC,EAAC,cAAa;AACrD,cAAQ,OAAO;AAAA,QACb,OAAO,CAAC,EAAC,OAAO,cAAa;AAC3B,sBAAY,OAAO,QAAQ;AAErB,gBAAA,mCAAmB,IAAI;AACzB,kBAAQ,SACV,aAAa,IAAI,QAAQ,IAAI,QAAQ,KAAK;AAG5C,gBAAM,UAAU,eAAe,MAAM,WAAW,YAAY;AAE5D,iBAAA,OAAO,SAAS,YAAY,GAErB,aAAa,IAAI,QAAQ,EAAE;AAAA,QAAA;AAAA,MACpC,CACD,GACD,QAAQ;AAAA,QACN,CAAC,EAAC,QAAA,OACC;AAAA,UACC,MAAM;AAAA,UACN,IAAI,QAAQ;AAAA,UACZ,UAAU,QAAQ;AAAA,QACpB;AAAA,MACJ;AAAA,IAAA,CACD;AAAA,IACD,iCAAiC;AAAA,MAC/B,CAAC,EAAC,QAAA,OACC;AAAA,QACC,MAAM;AAAA,QACN,IAAI,QAAQ;AAAA,MACd;AAAA,IACJ;AAAA,IACA,6BAA6B;AAAA,MAC3B,CAAC,EAAC,QAAA,OACC;AAAA,QACC,MAAM;AAAA,QACN,IAAI,QAAQ;AAAA,QACZ,UAAU,QAAQ;AAAA,MACpB;AAAA,IACJ;AAAA,IACA,iCAAiC,WAAW,CAAC,EAAC,SAAS,aACrD,YAAY,OAAO,UAAU,GACtB;AAAA,MACL,MAAM;AAAA,MACN,IAAI,QAAQ;AAAA,MACZ,aAAa,MAAM;AAAA,MACnB,WAAW,MAAM;AAAA,MACjB,SAAS,MAAM;AAAA,IAAA,EAElB;AAAA,EACH;AAAA,EACA,QAAQ;AAAA,IACN,sBAAsB;AAAA,MACpB,CAAC;AAAA,QACC;AAAA,MAAA,MAGI;AACE,cAAA,EAAC,UAAU,GAAA,IAAM;AAChB,eAAA,MAAM,MAAM,QAAQ,EAAE;AAAA,UAC3B;AAAA,YACE,CAAA,UACE,MAAM,SAAS,aACf,MAAM,SAAS,eACd,MAAM,SAAS,cAAc,MAAM,eAAe;AAAA,UACvD;AAAA;AAAA,UAEA,UAAU,aAAa;AAAA,QACzB;AAAA,MAAA;AAAA,IAEJ;AAAA,IACA,yBAAyB;AAAA,MACvB,OAAO;AAAA,QACL;AAAA,QACA;AAAA,MAAA,MAII;AACE,cAAA,EAAC,QAAQ,GAAA,IAAM;AACJ,eAAA,MAAM,OACpB,YAAY,IAAI;AAAA,UACf;AAAA,QAAA,CACD,EACA,MAAM,CAAK,MAAA;AACN,cAAA,EAAA,aAAa,SAAS,EAAE,SAAS;AAC/B,kBAAA;AAAA,QAAA,CACP;AAAA,MAAA;AAAA,IAIP;AAAA,IACA,oCAAoC;AAAA,MAClC,OAAO;AAAA,QACL;AAAA,QACA;AAAA,MAAA,MAII;AACE,cAAA,EAAC,QAAQ,aAAA,IAAgB;AAC/B,mBAAW,eAAe,cAAc;AACtC,cAAI,OAAO,QAAS;AACpB,gBAAM,OACH,YAAY,UAAU,kBAAkB,WAAW,GAAG;AAAA,YACrD,YAAY;AAAA,YACZ,iBAAiB;AAAA,YACjB;AAAA,UAAA,CACD,EACA,MAAM,CAAK,MAAA;AACN,gBAAA,EAAA,aAAa,SAAS,EAAE,SAAS;AAC/B,oBAAA;AAAA,UAAA,CACP;AAAA,QAAA;AAAA,MACL;AAAA,IACF;AAAA,EAEJ;AAAA,EACA,QAAQ;AAAA;AAAA,IAEN,4BAA4B,CAAC,EAAC,QAAO,MACnC,KAAK,IAAI,GAAG,QAAQ,2BAA2B,IAAI;AAAA,IACrD,2BAA2B,CAAC,EAAC,cAC3B,KAAK,IAAI,GAAG,QAAQ,0BAA0B,IAAI;AAAA,EAAA;AAExD,CAAC,EAAE,cAAc;AAAA;AAAA,EAGf,IAAI;AAAA,EAEJ,SAAS,CAAC,EAAC,aAAY;AAAA,IACrB,QAAQ,MAAM,OAAO,WAAW,EAAC,kBAAkB,IAAM;AAAA,IACzD,gBAAgB,MAAM;AAAA,IACtB,IAAI,MAAM;AAAA,IACV,QAAQ;AAAA,IACR,OAAO;AAAA,IACP,gBAAgB,CAAC;AAAA,IACjB,eAAe,CAAC;AAAA,IAChB,gBAAgB,CAAC;AAAA,IACjB,OAAO;AAAA,IACP,6BAA6B;AAAA,IAC7B,4BAA4B;AAAA,IAC5B,OAAO,MAAM;AAAA,EAAA;AAAA;AAAA,EAIf,OAAO,CAAC,+BAA+B;AAAA,EAEvC,IAAI;AAAA,IACF,QAAQ;AAAA,MACN,SAAS,CAAC,yBAAyB,gBAAgB;AAAA,IAAA;AAAA,EAEvD;AAAA,EACA,SAAS;AAAA,EACT,QAAQ;AAAA,IACN,cAAc;AAAA,MACZ,IAAI;AAAA,QACF,SAAS;AAAA,UACP,QAAQ;AAAA,UACR,SAAS,CAAC,8BAA8B;AAAA,QAAA;AAAA,MAC1C;AAAA,IAEJ;AAAA,IACA,YAAY;AAAA,MACV,IAAI;AAAA,QACF,SAAS;AAAA,QACT,WAAW;AAAA,QACX,OAAO;AAAA,MACT;AAAA,MACA,MAAM,CAAC,MAAM;AAAA,IACf;AAAA,IACA,gBAAgB;AAAA,MACd,IAAI;AAAA,QACF,SAAS;AAAA,UACP,QAAQ;AAAA,UACR,SAAS,CAAC,8BAA8B;AAAA,QAAA;AAAA,MAE5C;AAAA,MACA,OAAO;AAAA,QACL;AAAA,QACA;AAAA,MACF;AAAA,MACA,MAAM,CAAC,0BAA0B;AAAA,MACjC,MAAM,CAAC,OAAO;AAAA,IAChB;AAAA,IACA,cAAc;AAAA,MACZ,IAAI;AAAA,QACF,SAAS;AAAA,UACP,QAAQ;AAAA,QACV;AAAA,QACA,OAAO;AAAA,UACL,QAAQ;AAAA,QAAA;AAAA,MAEZ;AAAA,MACA,MAAM,CAAC,QAAQ,OAAO;AAAA,IACxB;AAAA,IACA,WAAW;AAAA,MACT,IAAI;AAAA,QACF,UAAU;AAAA,UACR,SAAS,CAAC,+BAA+B;AAAA,QAC3C;AAAA,QACA,WAAW;AAAA,MACb;AAAA,MACA,OAAO,CAAC,0BAA0B;AAAA,MAClC,SAAS;AAAA,MACT,QAAQ;AAAA,QACN,SAAS;AAAA,UACP,QAAQ;AAAA,YACN,KAAK;AAAA,YACL,IAAI;AAAA,YACJ,OAAO,CAAC,EAAC,eAAc;AAAA,cACrB,QAAQ,QAAQ;AAAA,cAChB,IAAI,QAAQ;AAAA,YAAA;AAAA,YAEd,SAAS;AAAA,cACP,QAAQ;AAAA,YACV;AAAA,YACA,QAAQ;AAAA,cACN,QAAQ;AAAA,cACR,SAAS;AAAA,gBACP;AAAA,gBACA;AAAA,cAAA;AAAA,YACF;AAAA,UAEJ;AAAA,UAEA,MAAM,CAAC,MAAM;AAAA,QACf;AAAA,QAEA,QAAQ;AAAA,UACN,OAAO,CAAC,2BAA2B;AAAA,UACnC,IAAI;AAAA,YACF,UAAU;AAAA,cACR,SAAS,CAAC,uBAAuB,+BAA+B;AAAA,YAAA;AAAA,UAEpE;AAAA,UACA,SAAS;AAAA,UAET,QAAQ;AAAA,YACN,UAAU;AAAA,cACR,IAAI;AAAA,gBACF,QAAQ;AAAA,kBACN,SAAS,CAAC,yBAAyB,gBAAgB;AAAA,kBACnD,QAAQ;AAAA,gBAAA;AAAA,cAEZ;AAAA,cACA,MAAM,CAAC,OAAO;AAAA,YAChB;AAAA,YACA,OAAO;AAAA,cACL,IAAI;AAAA,gBACF,QAAQ;AAAA,cACV;AAAA,cACA,MAAM,CAAC,OAAO;AAAA,YAChB;AAAA,YACA,YAAY;AAAA,cACV,IAAI;AAAA,gBACF,QAAQ;AAAA,kBACN,SAAS,CAAC,yBAAyB,gBAAgB;AAAA,gBAAA;AAAA,cAEvD;AAAA,cACA,QAAQ;AAAA,gBACN,KAAK;AAAA,gBACL,IAAI;AAAA,gBACJ,OAAO,CAAC,EAAC,cAAa;AAEd,wBAAA,oCAAoB,IAAI;AAC9B,yBAAA,cAAc,IAAI,QAAQ,IAAI,QAAQ,MAAM,GACrC;AAAA,oBACL,QAAQ,QAAQ;AAAA,oBAChB,cAAc;AAAA;AAAA,sBAEZ;AAAA,wBACE;AAAA,wBACA,qBAAqB,QAAQ,aAAa;AAAA,sBAAA;AAAA,oBAC5C;AAAA,kBAEJ;AAAA,gBACF;AAAA,gBACA,SAAS;AAAA,kBACP,QAAQ;AAAA,gBACV;AAAA,gBAEA,QAAQ;AAAA,kBACN,QAAQ;AAAA,kBACR,SAAS;AAAA,oBACP;AAAA,oBACA;AAAA,oBACA;AAAA,kBAAA;AAAA,gBACF;AAAA,cAEJ;AAAA;AAAA;AAAA;AAAA,cAIA,MAAM,CAAC,QAAQ,OAAO;AAAA,YACxB;AAAA,YACA,eAAe;AAAA,cACb,MAAM,CAAC,0BAA0B;AAAA,cACjC,OAAO;AAAA,gBACL,2BAA2B;AAAA,kBACzB,SAAS,CAAC,2BAA2B;AAAA,kBACrC,QAAQ;AAAA,gBAAA;AAAA,cAEZ;AAAA,cACA,IAAI;AAAA,gBACF,OAAO;AAAA,cACT;AAAA;AAAA;AAAA;AAAA;AAAA,cAKA,MAAM,CAAC,SAAS,OAAO;AAAA,YAAA;AAAA,UACzB;AAAA,QAEJ;AAAA,QAEA,aAAa;AAAA,UACX,MAAM,CAAC,0BAA0B;AAAA,UACjC,OAAO;AAAA,YACL,4BAA4B;AAAA,cAC1B,SAAS,CAAC,0BAA0B;AAAA,cACpC,QAAQ;AAAA,YAAA;AAAA,UAEZ;AAAA,UACA,IAAI;AAAA,YACF,OAAO;AAAA,UACT;AAAA,UACA,MAAM,CAAC,OAAO;AAAA,QAAA;AAAA,MAChB;AAAA,IACF;AAAA,EACF;AAEJ,CAAC;AAED,SAAS,kBACP,UACAF,QACA,cACA;AACA,QAAM,OAAO,WAAW,QAAQ,QAAQ,GAAGA,MAAK;AAC3C,SAAA,OAGE,OAAO,OAAO,MAAM,EAAC,MAAM,aAAa,CAAA,IAFtC;AAGX;AAEA,SAAS,QACP,UACA;AACA,MAAI,CAAC;AACI,WAAA;AAGT,QAAM,EAAC,MAAM,GAAG,IAAA,IAAO;AAChB,SAAA;AACT;","x_google_ignoreList":[1,2]}