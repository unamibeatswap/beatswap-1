"use strict";
Object.defineProperty(exports, "__esModule", { value: !0 });
var rxjs = require("rxjs"), decode = require("./_chunks-cjs/decode.cjs"), mendoza = require("mendoza"), toTransactions = require("./_chunks-cjs/toTransactions.cjs");
function omitRev(document) {
  if (document === void 0)
    return;
  const { _rev, ...doc } = document;
  return doc;
}
function applyMendozaPatch(document, patch, patchBaseRev) {
  if (patchBaseRev !== document?._rev)
    throw new Error(
      "Invalid document revision. The provided patch is calculated from a different revision than the current document"
    );
  const next = mendoza.applyPatch(omitRev(document), patch);
  return next === null ? void 0 : next;
}
function applyMutationEventEffects(document, event) {
  if (!event.effects)
    throw new Error(
      "Mutation event is missing effects. Is the listener set up with effectFormat=mendoza?"
    );
  const next = applyMendozaPatch(
    document,
    event.effects.apply,
    event.previousRev
  );
  return next ? { ...next, _rev: event.resultRev } : void 0;
}
function createDataset() {
  const documents = /* @__PURE__ */ new Map();
  return {
    set: (id, doc) => void documents.set(id, doc),
    get: (id) => documents.get(id),
    delete: (id) => documents.delete(id)
  };
}
function createReplayMemoizer(expiry) {
  const memo = /* @__PURE__ */ Object.create(null);
  return function(key, observable) {
    return key in memo || (memo[key] = observable.pipe(
      rxjs.finalize(() => {
        delete memo[key];
      }),
      rxjs.share({
        connector: () => new rxjs.ReplaySubject(1),
        resetOnRefCountZero: () => rxjs.timer(expiry)
      })
    )), memo[key];
  };
}
function filterMutationGroupsById(mutationGroups, id) {
  return mutationGroups.flatMap(
    (mutationGroup) => mutationGroup.mutations.flatMap(
      (mut) => toTransactions.getMutationDocumentId(mut) === id ? [mut] : []
    )
  );
}
let didEmitMutationsAccessWarning = !1;
function warnNoMutationsReceived() {
  didEmitMutationsAccessWarning || (console.warn(
    new Error(
      "No mutation received from backend. The listener is likely set up with `excludeMutations: true`. If your app need to now about mutations, make sure the listener is set up to include mutations"
    )
  ), didEmitMutationsAccessWarning = !0);
}
const EMPTY_ARRAY = [];
function createContentLakeStore(backend) {
  const local = createDataset(), remote = createDataset(), memoize = createReplayMemoizer(1e3);
  let stagedChanges = [];
  const remoteEvents$ = new rxjs.Subject(), localMutations$ = new rxjs.Subject(), stage$ = new rxjs.Subject();
  function stage(nextPending) {
    stagedChanges = nextPending, stage$.next();
  }
  function getLocalEvents(id) {
    return localMutations$.pipe(rxjs.filter((event) => event.id === id));
  }
  function getRemoteEvents(id) {
    return backend.observe(id).pipe(
      rxjs.filter(
        (event) => event.type !== "reconnect"
      ),
      rxjs.mergeMap((event) => {
        const oldLocal = local.get(id), oldRemote = remote.get(id);
        if (event.type === "sync") {
          const newRemote = event.document, [rebasedStage, newLocal] = toTransactions.rebase(
            id,
            oldRemote,
            newRemote,
            stagedChanges
          );
          return rxjs.of({
            type: "sync",
            id,
            before: { remote: oldRemote, local: oldLocal },
            after: { remote: newRemote, local: newLocal },
            rebasedStage
          });
        } else if (event.type === "mutation") {
          if (event.transactionId === oldRemote?._rev)
            return rxjs.EMPTY;
          const newRemote = applyMutationEventEffects(oldRemote, event), [rebasedStage, newLocal] = toTransactions.rebase(
            id,
            oldRemote,
            newRemote,
            stagedChanges
          );
          newLocal && (newLocal._rev = event.transactionId);
          const emittedEvent = {
            type: "mutation",
            id,
            rebasedStage,
            before: { remote: oldRemote, local: oldLocal },
            after: { remote: newRemote, local: newLocal },
            effects: event.effects,
            previousRev: event.previousRev,
            resultRev: event.resultRev,
            // overwritten below
            mutations: EMPTY_ARRAY
          };
          return event.mutations ? emittedEvent.mutations = decode.decodeAll(
            event.mutations
          ) : Object.defineProperty(
            emittedEvent,
            "mutations",
            warnNoMutationsReceived
          ), rxjs.of(emittedEvent);
        } else
          throw new Error(`Unknown event type: ${event.type}`);
      }),
      rxjs.tap((event) => {
        local.set(event.id, event.after.local), remote.set(event.id, event.after.remote), stage(event.rebasedStage);
      }),
      rxjs.tap({
        next: (event) => remoteEvents$.next(event),
        error: (err) => {
        }
      })
    );
  }
  function observeEvents(id) {
    return rxjs.defer(
      () => memoize(id, rxjs.merge(getLocalEvents(id), getRemoteEvents(id)))
    );
  }
  return {
    meta: {
      events: rxjs.merge(localMutations$, remoteEvents$),
      stage: stage$.pipe(
        rxjs.map(
          () => (
            // note: this should not be tampered with by consumers. We might want to do a deep-freeze during dev to avoid accidental mutations
            stagedChanges
          )
        )
      ),
      conflicts: rxjs.EMPTY
      // does nothing for now
    },
    mutate: (mutations) => {
      stagedChanges.push({ transaction: !1, mutations });
      const results = toTransactions.applyMutations(mutations, local);
      return toTransactions.commit(results, local), results.forEach((result) => {
        localMutations$.next({
          type: "optimistic",
          before: result.before,
          after: result.after,
          mutations: result.mutations,
          id: result.id,
          stagedChanges: filterMutationGroupsById(stagedChanges, result.id)
        });
      }), results;
    },
    transaction: (mutationsOrTransaction) => {
      const transaction = Array.isArray(
        mutationsOrTransaction
      ) ? { mutations: mutationsOrTransaction, transaction: !0 } : { ...mutationsOrTransaction, transaction: !0 };
      stagedChanges.push(transaction);
      const results = toTransactions.applyMutations(transaction.mutations, local);
      return toTransactions.commit(results, local), results.forEach((result) => {
        localMutations$.next({
          type: "optimistic",
          mutations: result.mutations,
          id: result.id,
          before: result.before,
          after: result.after,
          stagedChanges: filterMutationGroupsById(stagedChanges, result.id)
        });
      }), results;
    },
    observeEvents,
    observe: (id) => observeEvents(id).pipe(
      rxjs.map(
        (event) => event.type === "optimistic" ? event.after : event.after.local
      )
    ),
    optimize: () => {
      stage(toTransactions.squashMutationGroups(stagedChanges));
    },
    submit: () => {
      const pending = stagedChanges;
      return stage([]), rxjs.lastValueFrom(
        backend.submit(
          toTransactions.toTransactions(
            // Squashing DMP strings is the last thing we do before submitting
            toTransactions.squashDMPStrings(remote, toTransactions.squashMutationGroups(pending))
          )
        ).pipe(rxjs.toArray())
      );
    }
  };
}
exports.createContentLakeStore = createContentLakeStore;
//# sourceMappingURL=_unstable_store.cjs.map
